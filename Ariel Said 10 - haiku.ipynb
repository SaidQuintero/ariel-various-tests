{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "from azure.search.documents._generated.models import QueryCaptionResult\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "class AzureEmbeddings:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_embedding():\n",
    "        return AzureOpenAIEmbeddings(\n",
    "            azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "            openai_api_version=\"2023-08-01-preview\",\n",
    "            openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_URL\")\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_embeddings(content: str):\n",
    "        embeddings = AzureOpenAIEmbeddings(\n",
    "            azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "            openai_api_version=\"2023-08-01-preview\",\n",
    "            openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_URL\")\n",
    "        )\n",
    "\n",
    "        doc_result = embeddings.embed_documents([content])\n",
    "\n",
    "        return doc_result[0]\n",
    "\n",
    "# openai_client = AzureOpenAI(\n",
    "#     api_key=os.getenv(\"AZURE_CHAT_OPENAI_API_KEY\"), \n",
    "#     api_version=os.getenv(\"AZURE_CHAT_OPENAI_API_VERSION\"), \n",
    "#     azure_endpoint=os.getenv(\"AZURE_CHAT_OPENAI_ENDPOINT\")\n",
    "#     )\n",
    "openai_client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "groq_client = Anthropic(\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "embeddings_client = AzureEmbeddings()\n",
    "store_search_url: str = f'https://{os.getenv('AZURE_COGNITIVE_SEARCH_SERVICE_NAME')}.search.windows.net'\n",
    "search_client = SearchClient(\n",
    "            store_search_url, os.getenv(\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\"),\n",
    "            AzureKeyCredential(os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = \"\"\n",
    "\n",
    "\n",
    "def ensure_directory(directory_name):\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "\n",
    "\n",
    "def log(message):\n",
    "    global log_file_name\n",
    "    ensure_directory(\"logs\")\n",
    "    with open(log_file_name, \"a\") as file:\n",
    "        file.write(f\"{datetime.now()}\\n{message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_price = 0\n",
    "conversation_ct = 0\n",
    "conversation_pt = 0\n",
    "conversation_tt = 0\n",
    "\n",
    "\n",
    "def get_conversation_price(new_completion, model=\"gpt4o\"):\n",
    "    global conversation_price, conversation_ct, conversation_pt, conversation_tt\n",
    "    USD_price_in_COP = 4100\n",
    "\n",
    "    if model == \"gpt4o-mini\":\n",
    "        in_price = 0.0000006\n",
    "        out_price = 0.00000015\n",
    "    if model == \"gpt4o\":\n",
    "        in_price = 0.000015\n",
    "        out_price = 0.000005\n",
    "    if model == \"llama-3-8b\":\n",
    "        in_price = 0.00000005\n",
    "        out_price = 0.00000008\n",
    "    if model == \"llama-3-70b\":\n",
    "        in_price = 0.00000059\n",
    "        out_price = 0.0000007\n",
    "    if model == \"haiku\":\n",
    "        in_price = 0.00000025\n",
    "        out_price = 0.00000125\n",
    "\n",
    "    ct = new_completion.usage.completion_tokens\n",
    "    pt = new_completion.usage.prompt_tokens\n",
    "    tt = new_completion.usage.total_tokens\n",
    "    usd_total_price = (ct * out_price) + (pt * in_price)\n",
    "    cop_total_price = usd_total_price * USD_price_in_COP\n",
    "    conversation_price += cop_total_price\n",
    "    # conversation_ct += ct\n",
    "    # conversation_pt += pt\n",
    "    # conversation_tt += tt\n",
    "    # conversation_usd_total_price = (conversation_ct * out_price) + (\n",
    "    #     conversation_pt * in_price\n",
    "    # )\n",
    "    # conversation_cop_total_price = conversation_usd_total_price * USD_price_in_COP\n",
    "\n",
    "    print(\n",
    "        f\"üí∞ Conversation price: ${conversation_price} COP\\n\"\n",
    "        f\"   This message: ${cop_total_price} COP \"\n",
    "        f\"\"\n",
    "    )\n",
    "    log(\n",
    "        f\"üí∞ Conversation price: ${conversation_price} COP\\n\"\n",
    "        f\"   This message: ${cop_total_price} COP \"\n",
    "        f\"\"\n",
    "    )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### üîë Definir system prompt y tools\n",
    "\n",
    "messages = []\n",
    "conversation = []\n",
    "user_input = \"\"\n",
    "\n",
    "codes_to_laws = \"\"\"\n",
    "- C√≥digo Penal: Ley 599 de 2000\n",
    "- C√≥digo Civil: Ley 57 de 1887\n",
    "- C√≥digo de Comercio: Decreto 410 de 1971\n",
    "- C√≥digo de Procedimiento Civil: Decreto 1400 de 1970\n",
    "- C√≥digo de Procedimiento Penal: Ley 906 de 2004\n",
    "- C√≥digo General del Proceso: Ley 1564 de 2012\n",
    "- C√≥digo de la Infancia y la Adolescencia: Ley 1098 de 2006\n",
    "- C√≥digo Nacional de Polic√≠a: Decreto 1355 de 1970\n",
    "- C√≥digo de Recursos Naturales: Decreto 2811 de 1974\n",
    "- C√≥digo Electoral: Decreto 2241 de 1986\n",
    "- C√≥digo Disciplinario √önico: Ley 734 de 2002\n",
    "- C√≥digo Contencioso Administrativo: Ley 1437 de 2011 (anteriormente Decreto 1 de 1984)\n",
    "- C√≥digo de Minas: Ley 685 de 2001\n",
    "- C√≥digo de Educaci√≥n: Ley 115 de 1994\n",
    "- C√≥digo Nacional de Tr√°nsito Terrestre: Ley 769 de 2002\n",
    "- C√≥digo del Menor: Decreto 2737 de 1989\n",
    "- C√≥digo de Construcci√≥n del Distrito Capital de Bogot√°: Acuerdo 20 de 1995\n",
    "- C√≥digo de Construcci√≥n Sismo-Resistente: Acuerdo correspondiente (no especificado en los resultados)\n",
    "- C√≥digo de R√©gimen Departamental: Decreto 1222 de 1986\n",
    "- C√≥digo de R√©gimen Pol√≠tico y Municipal: Decreto-Ley 1333 de 1986\n",
    "- C√≥digo Penal Militar: Ley 522 de 1999\n",
    "- C√≥digo Penitenciario y Carcelario: Ley 65 de 1993\n",
    "- C√≥digo Procesal del Trabajo y del Seguro Social: Decreto-Ley 2158 de 1948\n",
    "- C√≥digo Sustantivo del Trabajo: Decreto 2663 de 1950\n",
    "- C√≥digo Sanitario Nacional: Ley 9 de 1979\n",
    "- C√≥digo General Disciplinario: Ley 1952 de 2019\n",
    "- C√≥digo Nacional de Seguridad y Convivencia Ciudadana: Ley 1801 de 2016\n",
    "- CODIGO DE POLICIA DE BOGOTA: ACUERDO 79 DE 2003\n",
    "- C√≥digo Penal Militar: Ley 522 de 1999\n",
    "- C√≥digo Penitenciario y Carcelario: Ley 65 de 1993\n",
    "- C√≥digo Procesal del Trabajo y del Seguro Social: Decreto-Ley 2158 de 1948\n",
    "- C√≥digo Sustantivo del Trabajo: Decreto 2663 de 1950\n",
    "- C√≥digo Sanitario Nacional: Ley 9 de 1979\n",
    "- C√≥digo General Disciplinario: Ley 1952 de 2019\n",
    "- C√≥digo Nacional de Seguridad y Convivencia Ciudadana: Ley 1801 de 2016\"\"\"\n",
    "\n",
    "\n",
    "get_next_chunk = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_next_chunk\",\n",
    "        \"description\": \"Use this tool to get when an important sources comes incomplete or the content is cut off. This tool will help you retrieve the following section of that given source.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"source_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"the unique identifier of the chunk that is incomplete. eg:'20240719192458csjscpboletinjurisprudencial20181219pdf_chunk30'\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"source_id\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "response_system_template = f\"\"\"\n",
    "Eres Ariel, un asistente de investigaci√≥n legal en jurisprudencia colombiana. Sigue estas instrucciones al responder:\n",
    "\n",
    "1. Consulta de Fuentes:\n",
    "- Tienes acceso a algunas fuentes que previamente has encontrado y seleccionado para generar esta respuesta. - Dentro de esas fuentes se encuentra toda la informaci√≥n disponible para responder. \n",
    "- Expresa toda la informaci√≥n que encuentres en las fuentes proporcionadas y que sea relevante para responder.\n",
    "- Si las fuentes no ayudan a responder la pregunta, responde: \"No encuentro informaci√≥n con esos t√©rminos, ¬øpuedes reformular tu consulta?\"\n",
    "\n",
    "2. Redacci√≥n de Respuestas:\n",
    "- S√© detallado y preciso, utilizando exclusivamente la informaci√≥n de las fuentes proporcionadas.\n",
    "- No incluyas informaci√≥n que no haya sido extra√≠da directamente de las fuentes. Est√° prohibido.\n",
    "- No inventes informaci√≥n por ning√∫n motivo. No alucines.\n",
    "\n",
    "3. Citaci√≥n de Fuentes:\n",
    "- Cita el mayor n√∫mero de fuentes aplicables.\n",
    "- Utiliza corchetes para referenciar la fuente con el ID del fragmento sin modificarlo, por ejemplo: [12345_id_de_ejemplo].\n",
    "- No combines fuentes; lista cada fuente por separado.\n",
    "\n",
    "3. Formato de Respuesta:\n",
    "- Escribe tus respuestas en formato HTML, sin incluir los tags \"```html\" al principio o al final.\n",
    "- Utiliza etiquetas HTML est√°ndar como <p>, <strong>, <em>, etc.\n",
    "\n",
    "5. Interpretaci√≥n de Categor√≠as:\n",
    "- Prioriza las fuentes seg√∫n su categor√≠a:\n",
    "    1. Constitucional: Es la norma m√°xima y m√°s importante establecida por el gobierno del pa√≠s. \n",
    "    2. Legal: Es la que le sigue en importancia y son las leyes dictadas por el Congreso. \n",
    "    3. Infralegal: Le sigue en importancia a la categor√≠a Legal y comprende decretos, resoluciones y otros documentos oficiales de autoridades p√∫blicas como ministerios y superintendencias. \n",
    "    4. Jurisprudencia: Est√°n por debajo de las leyes y las normas infralegales. Son proferidas por jueces de la rep√∫blica y demuestran c√≥mo se ha ejercido la ley en el pasado. Las sentencias y autos de la Corte Constitucional est√°n por encima de la ley,\n",
    "    5. Doctrina: Son documentos o libros escritos por autores del derecho que no son parte de la ley pero ayudan a darle una interpetaci√≥n a la ley.\n",
    "- Da mayor importancia a las fuentes m√°s actuales.\n",
    "\n",
    "6. Precisi√≥n Legal:\n",
    "- Siempre dale m√°s importancia a la fuente primaria. Si debes citar una ley, art√≠culo o norma, cita la fuente directa, es decir, esa ley, art√≠culo o normal.\n",
    "- Las fuentes secundarias te ayudar√°n a entender la interpretaci√≥n sobre las fuentes primarias.\n",
    "- No confundas leyes o art√≠culos; si el usuario pregunta por una ley espec√≠fica, ignora extractos de otras leyes.\n",
    "- Utiliza las fuentes para dar una respuesta completa y darle al usuario informaci√≥n adicional que pueda serle de ayuda.\n",
    "- Cita textualmente cuando necesites mencionar el contenido un art√≠culo, ley u otro documento y si el tama√±o de este lo permite.\n",
    "\n",
    "7. Evita Imprecisiones:\n",
    "- En caso de encontrar informaci√≥n contradictoria, se√±√°lala y sugiere una posible causa.\n",
    "- No te salgas del tema de la pregunta del usuario.\n",
    "- En caso que el usuario haya dado informaci√≥n incorrecto o imprecisa, se√±√°lala y da un argumento.\n",
    "- Si la ley, la jurisprudencia y la doctrina tienen respuestas diferentes o interpretaciones diferentes para la misma pregunta, se√±ala las distintas perspectivas.\n",
    "\"\"\"\n",
    "\n",
    "# Incluir que el usuario puede estar proporcionando alguna informaci√≥n que es falsa, en ese caso debe apuntarla y argumentar con la informaci√≥n de las fuentes el porqu√© es falsa.\n",
    "# Incluir que se√±ale informaci√≥n contradictoria si es relevante en las fuentes.\n",
    "# Que siempre le d√© m√°s importancia a las fuentes primarias.\n",
    "# Que las fuentes secundarias ayudan a dar interpretaci√≥n y contexto.\n",
    "\n",
    "query_system_template = f\"\"\"Eres un asistente de investigaci√≥n con el objetivo de buscar en una base de conocimiento legal con cientos de miles de documentos, fuentes confiables y precisas acerca de la pregunta del usuario. La base de conocimientos est√° alojada en Azure AI Search y debes generar un query por cada b√∫squeda que necesitas y que que conserve todo el significado sem√°ntico de la idea. \n",
    "\n",
    "Los documentos est√°n guardados en fragmentos con los siguientes campos:\n",
    "- id: Identificador √∫nico del fragmento\n",
    "- title: T√≠tulo del documento\n",
    "- author: Autor del documento\n",
    "- keywords: Tema legal, puede ser: General, Constitucional, Internacional_Publico, Internacional_Privado, Penal, Financiero, entre otros.\n",
    "- category: Tipo de documento legal. Las opciones son: Jurisprudencia, Doctrina, Constitucional, Legal, Infralegal y Otros_temas_legales. \n",
    "- page: P√°gina de la que fue extra√≠do el fragmento.\n",
    "- year: A√±o en el que se public√≥ el documento.\n",
    "- content: 500 tokens de contenido, fragmento o extracto del documento. Son solo 500 tokens del documento completo.\n",
    "\n",
    "Pasos para generar la b√∫squeda:\n",
    "1. Identifica qu√© informaci√≥n necesitas buscar para responder de forma precisa y completa al usuario.\n",
    "2. Solo puedes hacer 3 b√∫squedas, as√≠ que elabora un plan de investigaci√≥n donde organizar√°s c√≥mo puedes distribuir tus b√∫squedas en caso que necesites hacer m√°s de 1.  \n",
    "3. Genera un query por cada b√∫squedad que necesitas ejecutar. Puedes generar un m√°ximo de 3 b√∫squedas. Puedes buscar cualquier cosa, desde teor√≠as del derecho, hasta leyes o una b√∫squeda general.\n",
    "4. Cada b√∫squeda solo puede contener 1 idea. Eso significa que si debes comparar teor√≠as, definiciones, conceptos, leyes, art√≠culos o documentos, debes buscarlos por separado.\n",
    "5. Por cada b√∫squeda, da una breve explicaci√≥n donde argumentes por qu√© necesitas hacer esa b√∫squeda.\n",
    "\n",
    "Cada query debe cumplir con las siguientes checklist:\n",
    "[] Debe ser una idea sem√°nticamente completa.\n",
    "[] Debe contener palabras clave. Por ejemplo: conceptos, teor√≠as, art√≠culos, leyes, normas, t√≠tulos de documento, o palabras contextuales como 'cu√°ndo', 'd√≥nde', 'lugar', 'momento', 'tiempo', etc.\n",
    "[] Debe ser conciso y preciso. No debe ser demasiado largo. \n",
    "\n",
    "Recomendaciones adicionales:\n",
    "- No todos los query deben ser espec√≠ficos para un documento, recuerda que solo puedes hacer m√°ximo 3 b√∫squedas, as√≠ que en ocasiones puedes obtener mejor informaci√≥n si buscas conceptos m√°s generales en vez de un documento espec√≠fico.\n",
    "- El query puede ser a forma de pregunta.\n",
    "\n",
    "Ejemplos de buenos query:\n",
    "1. Pregunta: '¬øCu√°ndo se entiende por terminada una condena?' - Query: '¬øcu√°ndo termina una condena?'\n",
    "2. Pregunta: '¬øQu√© dice el art√≠culo 223 del c√≥digo penal?' - Query: 'art√≠culo 223 C√≥digo Penal Ley 599 de 2000 '\n",
    "3. Pregunta: '¬øEn qu√© art√≠culo de la Constituci√≥n se consagra el bloque de constitucionalidad?' - Query: 'bloque de constitucionalidad Constituci√≥n'\n",
    "4. Pregunta: '¬øCu√°ndo se consuma el hurto?' - Query: '¬øcu√°ndo se consuma el hurto?'\n",
    "\n",
    "Esta es una lista de los c√≥digos en colombia y sus respectiva ley. Si necesitas buscar alguna de estas fuentes, debes incluir ambas refencias en tu query: {codes_to_laws}\n",
    "\n",
    "Genera tu respuesta en formato JSON Array. Aunque generes solo 1 b√∫squeda, mete el JSON en un array[] con el siguiente schema:\n",
    "{{\"searches\":[{{\"search_query\":\"El query de b√∫squeda completo. Este debe cumplir con todos los requitiso.\",\"reason\":\"Argumento de porqu√© necesitas hacer esta b√∫squeda.\"}}]}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "query_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"search_query\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"searches\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"search_query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"El query de b√∫squeda completo. Este debe cumplir con todos los requitiso.\",\n",
    "                            },\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Argumento de porqu√© necesitas hacer esta b√∫squeda.\",\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"search_query\",\n",
    "                            \"reason\",\n",
    "                        ],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                },\n",
    "                #     \"strategy\": {\n",
    "                #         \"type\": \"string\",\n",
    "                #         \"description\": \"Describe brevemente qu√© estrategia de investigaci√≥n vas a ejecutar y porqu√©.\",\n",
    "                #     },\n",
    "            },\n",
    "            \"required\": [\"searches\"],\n",
    "            # \"required\": [\"searches\", \"strategy\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "selected_sources_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"selected_sources\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sources\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"source_id\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"ID de la fuente que seleccionaste\",\n",
    "                            },\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Argumento de porqu√© seleccionaste esta fuente.\",\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"source_id\",\n",
    "                            \"reason\",\n",
    "                        ],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                },\n",
    "                \"selection_strategy\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Describe brevemente porqu√© seleccionaste de esta manera las fuentes. ¬øCu√°l fue tu estrategia y porqu√© no seleccionaste otros documentos?\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sources\", \"selection_strategy\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "# Agregar un campo para identificar fuentes cortadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(completion_messages):\n",
    "    log(f\"{json.dumps(completion_messages, indent=4)}\\n\")\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=completion_messages,\n",
    "        tools=[get_next_chunk],\n",
    "        temperature=0.2,\n",
    "        n=1,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "    log(response)\n",
    "    get_conversation_price(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "def choose_sources_completion(completion_messages):\n",
    "    log(f\"{json.dumps(completion_messages, indent=4)}\\n\")\n",
    "    response = groq_client.messages.create(\n",
    "        max_tokens=2000,\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=completion_messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    log(response)\n",
    "    get_conversation_price(response, model=\"haiku\")\n",
    "    return response\n",
    "\n",
    "\n",
    "def generate_query(query_messages):\n",
    "    log(f\"{json.dumps(query_messages, indent=4)}\\n\")\n",
    "    response = groq_client.messages.create(\n",
    "        max_tokens=2000,\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=query_messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    log(response)\n",
    "    get_conversation_price(response, model=\"haiku\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_search_results(docs_list):\n",
    "    print(f\"üìã Agarrando todos los resultados ...\")\n",
    "    documents = []\n",
    "    try:\n",
    "        docs_list = list(docs_list)\n",
    "        print(f\"üìã Formateando resultados ...\")\n",
    "        for index, document in enumerate(docs_list, start=1):\n",
    "            captions: QueryCaptionResult = document.get(\"@search.captions\", \"\")\n",
    "            captions_text = \" // \".join([caption.text for caption in captions]) if captions is not None else \"\"\n",
    "            doc_formatted = {\n",
    "                \"position\" : index,\n",
    "                \"score\": document.get(\"@search.score\", 10),\n",
    "                \"rerank\": document.get(\"@search.reranker_score\", 10),\n",
    "                \"captions\": captions_text,\n",
    "                \"id\": document[\"id\"],\n",
    "                \"title\": document[\"title\"],\n",
    "                \"author\": document[\"author\"],\n",
    "                \"keywords\": document[\"keywords\"],\n",
    "                \"category\": document[\"category\"],\n",
    "                \"page\": document[\"page\"],\n",
    "                \"year\": document[\"year\"],\n",
    "                \"has_copyright\": document[\"has_copyright\"],\n",
    "                \"file_path\": document[\"file_path\"],\n",
    "                \"external_id\": document[\"external_id\"],\n",
    "                \"content\": document[\"content\"],\n",
    "            }\n",
    "            documents.append(doc_formatted)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    log(\n",
    "        f\">>>>>>format_search_results:\\n\"\n",
    "        f\"{json.dumps(documents, indent=4)}\"\n",
    "        )\n",
    "    return documents\n",
    "\n",
    "def filter_docs(doc_list):\n",
    "    print(f\"üßπ Eliminando fuentes irrelevantes o duplicadas ...\")\n",
    "    filtered_docs = []\n",
    "    seen_docs = set()\n",
    "    \n",
    "    for doc in doc_list:\n",
    "        score = doc.get(\"score\", 10) \n",
    "        rerank = doc.get(\"rerank\", 10) \n",
    "        content = doc[\"content\"] \n",
    "        if (\n",
    "            content not in seen_docs\n",
    "            and (rerank > 2\n",
    "            or score > 0.17)\n",
    "        ):\n",
    "            filtered_docs.append(doc)\n",
    "            seen_docs.add(content)\n",
    "    print(f\"üßπ Docs filtrados. De {len(doc_list)} pasaron {len(filtered_docs)} ...\")\n",
    "    log(f\"üßπ Docs filtrados. De {len(doc_list)} pasaron {len(filtered_docs)} ...\\n\"\n",
    "    f\"{json.dumps(filtered_docs, indent=4)}\")\n",
    "    return filtered_docs\n",
    "\n",
    "def add_doc_to_context(docs_list):\n",
    "    print(f\"üìã Agregando fuentes al contexto ...\")\n",
    "    sources = \"\"\n",
    "    counter = 0\n",
    "    \n",
    "    for document in docs_list:\n",
    "        counter += 1\n",
    "        sources += (\n",
    "            f\"Fuente:\\n\"\n",
    "            f\"{document.get(\"reason\", \"\")}\"\n",
    "            f\"id: {document[\"id\"]}\\n\"\n",
    "            f\"title: {document[\"title\"]}\\n\"\n",
    "            f\"author: {document[\"author\"]}\\n\"\n",
    "            f\"year: {document[\"year\"]}\\n\"\n",
    "            f\"keywords: {document[\"keywords\"]}\\n\"\n",
    "            f\"category: {document[\"category\"]}\\n\"\n",
    "            f\"page: {document[\"page\"]}\\n\"\n",
    "            f\"content: {document[\"content\"]}\\n\"\n",
    "            f\"\\n\\n\"\n",
    "        )      \n",
    "    log(\n",
    "        f\"To add in Context: \\n\"\n",
    "        f\"{json.dumps({\"sources\":sources}, indent=4)}\"\n",
    "        )\n",
    "    print(f\"üìã {counter} fuentes agregadas ...\")\n",
    "    return sources\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_chunks(text_query):\n",
    "    log(f\"üîé Buscando documentos: {text_query} ...\")\n",
    "    print(f\"üîé Buscando documentos: {text_query} ...\")\n",
    "    results_num = 50\n",
    "    vector_query = embeddings_client.generate_embeddings(content=text_query)\n",
    "\n",
    "    results = search_client.search(\n",
    "        search_text=text_query,\n",
    "        vector_queries=[\n",
    "            {\n",
    "                \"vector\": vector_query,\n",
    "                \"k\": results_num,\n",
    "                \"fields\": \"content_vector\",\n",
    "                \"kind\": \"vector\",\n",
    "                # \"exhaustive\": True,\n",
    "            }\n",
    "        ],\n",
    "        top=results_num,\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name=\"default\",\n",
    "        query_caption=\"extractive|highlight-false\",\n",
    "        scoring_profile=\"legal\",\n",
    "        scoring_parameters=[\n",
    "            \"tagx6-Constitucional\",\n",
    "            \"tagx5-Legal\",\n",
    "            \"tagx4-Infralegal\",\n",
    "            \"tagx3-Jurisprudencia\",\n",
    "            \"tagx2-Doctrina\",\n",
    "        ],\n",
    "    )\n",
    "    results_formatted = format_search_results(results)\n",
    "    restults_filtered = filter_docs(results_formatted)\n",
    "\n",
    "    return restults_filtered[:25]\n",
    "\n",
    "\n",
    "def get_next_chunks(id):\n",
    "    log(f\"‚è©Ô∏è Buscando los chunks siguientes de {id} ...\")\n",
    "    print(f\"‚è©Ô∏è Buscando los chunks siguientes de {id} ...\")\n",
    "    pattern = r\"^(.*_chunk)(\\d+)$\"\n",
    "    match = re.search(pattern, id)\n",
    "\n",
    "    if match:\n",
    "        prefix = match.group(1)\n",
    "        chunk_number = int(match.group(2))\n",
    "        next_chunks_result = search_client.search(\n",
    "            filter=f\"id eq '{prefix}{chunk_number + 1}' or id eq '{prefix}{chunk_number + 2}'\",\n",
    "            top=2,\n",
    "        )\n",
    "        return format_search_results(list(next_chunks_result))\n",
    "\n",
    "\n",
    "def get_next_chunk_tool(source_id):\n",
    "    next_chunks = get_next_chunks(source_id)\n",
    "    log(f\"Continuaci√≥n de {source_id}:\\n{add_doc_to_context(next_chunks)}\")\n",
    "    return f\"Continuaci√≥n de {source_id}:\\n{add_doc_to_context(next_chunks)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_message(new_message):\n",
    "    global messages, conversation\n",
    "\n",
    "    if isinstance(new_message, dict):\n",
    "        role = new_message.get(\"role\")\n",
    "        content = new_message.get(\"content\")\n",
    "    else:\n",
    "        role = new_message.role\n",
    "        content = new_message.content\n",
    "\n",
    "    if role == \"assistant\":\n",
    "        if new_message.tool_calls:\n",
    "            tool_calls = new_message.tool_calls\n",
    "            tool_calls_formatted = []\n",
    "            for tool_call in tool_calls:\n",
    "                tool_calls_formatted.append(\n",
    "                    {\n",
    "                        \"id\": tool_call.id,\n",
    "                        \"function\": {\n",
    "                            \"arguments\": str(json.loads(tool_call.function.arguments)),\n",
    "                            \"name\": tool_call.function.name,\n",
    "                        },\n",
    "                        \"type\": \"function\",\n",
    "                    }\n",
    "                )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"tool_calls\": tool_calls_formatted,\n",
    "                },\n",
    "            )\n",
    "            return messages  ## Assistant call tools\n",
    "        elif content:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "            return messages  ## Assistant talk\n",
    "    elif role == \"tool\":\n",
    "        messages.append(new_message)\n",
    "        return messages  ## Tool reponse\n",
    "    else:\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tools(tool_calls):\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        tool_args = json.loads(tool_call.function.arguments)\n",
    "        if tool_name == \"get_next_chunk\":\n",
    "            content = get_next_chunk_tool(tool_args.get(\"source_id\"))\n",
    "\n",
    "        new_tool_message = {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": tool_name,\n",
    "            \"content\": content,\n",
    "        }\n",
    "\n",
    "        append_message(new_message=new_tool_message)\n",
    "\n",
    "    print(\">> ü§ñ Generando respuesta ...\")\n",
    "    new_assistant_completion = generate_completion()\n",
    "    new_assistant_message = new_assistant_completion.choices[0].message\n",
    "    append_message(new_message=new_assistant_message)\n",
    "\n",
    "    if new_assistant_message.content:\n",
    "        return print(\"üí¨ Assistant:\" + new_assistant_message.content)\n",
    "    else:\n",
    "        return call_tools(\n",
    "            tool_calls=new_assistant_message.tool_calls,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(user_prompt=None):\n",
    "    if user_prompt:\n",
    "        get_answer(user_prompt)\n",
    "    else:\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Exiting chat...\")\n",
    "                break\n",
    "            get_answer(user_input)\n",
    "\n",
    "\n",
    "def get_answer(user_prompt):\n",
    "    global messages, log_file_name, user_input\n",
    "\n",
    "    user_input = user_prompt\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%m-%d %H:%M\")\n",
    "    log_file_name = f\"logs/{current_time} - {user_input[:50]}.log\"\n",
    "\n",
    "    print(\"üôé‚Äç‚ôÇÔ∏è User: \" + user_input)\n",
    "    log(f\"User input: {user_input}\")\n",
    "\n",
    "    query_prompt_message = {\"role\": \"system\", \"content\": query_system_template}\n",
    "    response_prompt_message = {\"role\": \"system\", \"content\": response_system_template}\n",
    "    query_user_prompt_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Genera uno o varias b√∫squedas para responder esta pregunta: {user_input}\",\n",
    "    }\n",
    "\n",
    "    query_messages = [\n",
    "        query_prompt_message,\n",
    "        *messages,\n",
    "        query_user_prompt_message,\n",
    "    ]\n",
    "\n",
    "    print(\"ü§ñ Generando queries con la pregunta del usuario ...\")\n",
    "    first_query_completion = generate_query(query_messages)\n",
    "    first_search_terms = json.loads(\n",
    "        first_query_completion.choices[0].message.content\n",
    "    ).get(\"searches\")\n",
    "    print(f\"ü§ñ {len(first_search_terms)} b√∫squedas generadas ...\")\n",
    "\n",
    "    sources_found = []\n",
    "    search_result_prompt = \"\"\n",
    "    search_reasons = \"\"\n",
    "\n",
    "    for search in first_search_terms:\n",
    "        search_query = search.get(\"search_query\")\n",
    "        query_reason = search.get(\"reason\")\n",
    "        # print(f\"Buscando '{search_query}': {query_reason}\")\n",
    "        print(query_reason)\n",
    "        query_results = search_for_chunks(search_query)\n",
    "        sources_found += query_results\n",
    "        search_reasons += f\"{query_reason} Por eso buscar√© '{search_query}'.\\n\"\n",
    "        # search_queries += f\"'{search_query}',\"\n",
    "        sources_to_add = add_doc_to_context(query_results)\n",
    "        search_result_prompt += f\"{query_reason}.\\nPor eso b√∫squ√© '{search_query}' y encontr√© estas fuentes:\\n{sources_to_add}\\n\\n\"\n",
    "\n",
    "    # Meter aqu√≠ razonamiento de qu√© informaci√≥n ha encontrado en esta b√∫squeda.\n",
    "\n",
    "    reasoning_results_prompt_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": search_result_prompt,\n",
    "    }\n",
    "    reasoning_prompt_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Necesito que plantees una nueva y mejorada estrategia de b√∫squeda para responder al usuario de forma completa:\\n1. Resume La Informaci√≥n: Lee y absorbe toda la informaci√≥n de las fuentes y utiliza los hallazgos m√°s relevantes para mi investigaci√≥n.\\n2. Genera Una Nueva B√∫squeda: Con estos nuevos hallazgos sugiere un m√°ximo de 3 b√∫squedas que ayuden a conseguir informaci√≥n precisa y relevante para reponder a la pregunta del usuario.\\n3. Dime por qu√© estas 3 nuevas b√∫squedas me ayudar√≠an en mi investigaci√≥n.\\nRecuerda que cada query debe cumplir con el checklist y que estamos buscando documentos para responder a: {user_input}\",\n",
    "    }\n",
    "\n",
    "    query_messages += [\n",
    "        reasoning_results_prompt_message,\n",
    "        reasoning_prompt_message,\n",
    "    ]\n",
    "\n",
    "    print(\"ü§ñ Generando nuevas b√∫squedas con la nueva informaci√≥n ...\")\n",
    "    second_query_completion = generate_query(query_messages)\n",
    "    second_search_terms = json.loads(\n",
    "        second_query_completion.choices[0].message.content\n",
    "    ).get(\"searches\")\n",
    "    print(f\"ü§ñ {len(second_search_terms)} b√∫squedas generadas ...\")\n",
    "\n",
    "    query_reasons = \"\"\n",
    "    # search_strategy = first_search_terms.get(\"strategy\")\n",
    "    # print(f\"{search_strategy}\")\n",
    "    for search in second_search_terms:\n",
    "        search_query = search.get(\"search_query\")\n",
    "        query_reason = search.get(\"reason\", \"\")\n",
    "        print(f\"Buscando '{search_query}': {query_reason}\")\n",
    "        # print(query_reason)\n",
    "        query_results = search_for_chunks(search_query)\n",
    "        sources_found += query_results\n",
    "        query_reasons += f\"{query_reason} Por eso busqu√© '{search_query}'. \"\n",
    "\n",
    "    # return\n",
    "    sources_found_filtered = filter_docs(sources_found)\n",
    "    sources_to_add = add_doc_to_context(sources_found_filtered)\n",
    "\n",
    "    response_prompt_message = {\"role\": \"system\", \"content\": f\"\"\"{response_system_template}\\n\\nGenera tu respuesta en formato JSON con el siguiente schema:{{\"sources\":[{{\"source_id\":\"ID de la fuente que seleccionaste\"}}]}}\"\"\"}\n",
    "    select_user_prompt_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Busca informaci√≥n relevante y selecciona las mejores fuentes para responder a: {user_input}\",\n",
    "    }\n",
    "    select_prompt_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"\"\"{query_reasons}.\\n\\nResultados de mis b√∫squedas:\\n{sources_to_add}\\n\\nEjectuaste una b√∫squeda con lo que el usuario te pregunt√≥ y encontraste fuentes que pueden servirte, ahora debes escoger las mejores. Sigue las siguientes instrucciones:\\n1. Revisa todos los extractos obtenidos con tu b√∫squeda y selecciona m√≠nimo 3 y m√°ximo 10 fuentes que te sirvan para responder al usuario. No pueden ser menos de 3 y al menos 2 de esas deben ser Jurisprudencia o Doctrina.\\n2. Enlista las fuentes que escogiste e identif√≠calas por su ID y por ning√∫n motivo en absoluto cambies el valor del ID o n√∫mero de chunk de una fuente. Ord√©nalas por importancia, posicionando de primero la que consideres m√°s relevante o m√°s cercanas a lo que el usuario pidi√≥.\\n3.(Opcional) Intenta seleccionar un grupo de fuentes donde puedas dar una respuesta completa a la pregunta, se√±alar contradicciones en las fuentes, dar informaci√≥n complementaria relevante y se√±alar diversos puntos de vista al respecto lo que el usuario pregunta.\\n4. Al lado de cada fuente que seleccionaste escribe una muy breve explicaci√≥n argumentando porqu√© la escogiste y porqu√© ayuda a responder mejor la solicitud del usuario.\\n5. Toda la informaci√≥n debe provenir de lo que dicen las fuentes, no inventes ni des informaci√≥n adicional que no est√©n presentes en las fuentes.\\n6. Debes seleccionar al menos 2 fuentes que sean Jurisprudencia o Doctrina, ya que estos ayudar√°n a dar contexto a las leyes en su aplicaci√≥n.\\nRecomendaciones adicionales\\n- Dale m√°s importancia a las fuentes que son extractos del documento que el usuario pidio.\\n- Conforma tu selecci√≥n tanto de fuentes primarias como secundarias si esto ayuda a reponder mejor la pregunta.\\n- Las fuentes que selecciones es la √∫nica informaci√≥n que vas a tener disponible para responder a la pregunta, as√≠ que debes escoger fuentes que dentro de su contenido se encuentre la informaci√≥n.\\n- En tu razonamiento, si escogiste una fuente porque incluye cierta ley, art√≠culo, teor√≠a o menci√≥n de algo especial, qu√© ley, art√≠culo, teor√≠a, etc es a la que te refieres.\\n- No selecciones fuentes repetitivas, busca tener diversidad en tus fuentes.\\n- En el ID de la fuente encontrar√°s el n√∫mero del chunk ej: '..._chunk10', esto significa que el siguiente chunk ('...chunk11') es el fragmento que le sigue al documento. Ten en cuenta esto para que sepas que si un contenido importante est√° cortado en un chunk, puedes agarrar el siguientes tambi√©n.\\n- Ten en cuenta que los nombres de algunos codigos hacen referencia a una ley, decreto o articulo. Aqui tienes un listado para que te guies:\\n{codes_to_laws}\"\"\",\n",
    "    }\n",
    "\n",
    "    selection_messages = [\n",
    "        response_prompt_message,\n",
    "        *messages,\n",
    "        select_user_prompt_message,\n",
    "        select_prompt_message,\n",
    "        # select_instructions_prompt_message,\n",
    "    ]\n",
    "\n",
    "    print(\"ü§ñ Escogiendo las mejores fuentes para responder al usuario ...\")\n",
    "    selected_sources_to_add = []\n",
    "    sources_at_end = \"\"\n",
    "    selected_sources_completion = choose_sources_completion(selection_messages)\n",
    "    selected_sources = json.loads(\n",
    "        selected_sources_completion.choices[0].message.content\n",
    "    ).get(\"sources\")\n",
    "    for index, source in enumerate(selected_sources, start=1):\n",
    "        source_id = source.get(\"source_id\")\n",
    "        source_reason = source.get(\"reason\")\n",
    "        for source in sources_found_filtered:\n",
    "            if source[\"id\"] == source_id:\n",
    "                source[\"reason\"] = source_reason\n",
    "                sources_at_end += f\"{index}. {source[\"title\"]} - P√°gina {source[\"page\"]}<br>\\n\"\n",
    "                selected_sources_to_add.append(source)\n",
    "        print(f\"{index}.[{source_id}]: {source_reason}\")\n",
    "\n",
    "    # return\n",
    "    sources_to_add = add_doc_to_context(selected_sources_to_add)\n",
    "    # TODO: Agregar hasta 3 por cada query que excedan 2.8/3 como score sem√°ntico.\n",
    "    # Quiz√°s ponerle cap de 6 fuentes m√°ximo en total ordenadas por score sem√°ntico, porque pueden ser 18 si ambas b√∫squeda es de 3 queries y tiene matchs fuertes\n",
    "    # TODO: Esto podr√≠a ser que los reorganice convirtiendo en vectores en la pregunta y compar√°ndolos con los vectores de cada chunk, ChatGPT me di√≥ esa idea... o cohere.\n",
    "\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input,\n",
    "    }\n",
    "    sources_prompt_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Fuentes econtradas:\\n{sources_to_add}\",\n",
    "    }\n",
    "\n",
    "    response_messages = [\n",
    "        response_prompt_message,\n",
    "        *messages,\n",
    "        user_message,\n",
    "        sources_prompt_message,\n",
    "    ]\n",
    "\n",
    "    response_completion = generate_completion(response_messages)\n",
    "    print(response_completion.choices[0].message.content)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"\\n\\n<p>{sources_at_end}</p>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar con all > Dejarlo default mejor ‚úÖ\n",
    "Probar full text search > Malos resultados ‚úÖ\n",
    "Filtrar por semantic rerank score de 2 o m√°s. ‚úÖ\n",
    "Filtrar por score de 1.7 o m√°s. ‚úÖ\n",
    "Incluir hasta 25 fuentes por query.\n",
    "Otro proceso del mini 4o donde seleccione las mejores fuentes para responder la respuesta ‚úÖ\n",
    "Pedir que razone porqu√© escogi√≥ esos query ‚úÖ\n",
    "Probar corriendo el proyecto en un .py normal y ponerle timers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üôé‚Äç‚ôÇÔ∏è User: ¬øQu√© dice el art√≠culo 250 de la Constituci√≥n?\n",
      "ü§ñ Generando queries con la pregunta del usuario ...\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m¬øQu√© dice el art√≠culo 250 de la Constituci√≥n?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_conversation\u001b[39m(user_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_prompt:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mget_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[21], line 38\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m     31\u001b[0m query_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     32\u001b[0m     query_prompt_message,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;241m*\u001b[39mmessages,\n\u001b[1;32m     34\u001b[0m     query_user_prompt_message,\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mü§ñ Generando queries con la pregunta del usuario ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m first_query_completion \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m first_search_terms \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\n\u001b[1;32m     40\u001b[0m     first_query_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     41\u001b[0m )\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mü§ñ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(first_search_terms)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m b√∫squedas generadas ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mgenerate_query\u001b[0;34m(query_messages)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_query\u001b[39m(query_messages):\n\u001b[1;32m     30\u001b[0m     log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(query_messages,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-3-haiku-20240307\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     log(response)\n\u001b[1;32m     38\u001b[0m     get_conversation_price(response, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaiku\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/resources/messages.py:878\u001b[0m, in \u001b[0;36mMessages.create\u001b[0;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[1;32m    872\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    875\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    876\u001b[0m     )\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1259\u001b[0m     )\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1050\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
     ]
    }
   ],
   "source": [
    "run_conversation(\"¬øQu√© dice el art√≠culo 250 de la Constituci√≥n?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üôé‚Äç‚ôÇÔ∏è User: Tienes el siguiente caso: Un estudiante de sexto de bachillerato de un colegio privado cat√≥lico es echado del colegio por tener el pelo largo. √âl laega que en el libre desarrollo de su personalidad, puede llevar el pelo como quiera. Por eso, present√≥ una tutela para que lo reintegren al colegio. El colegio ha contestado a la tutela indicando que, al ser una instituci√≥n privada, ellos pueden reservarse el derecho de admisi√≥n y dictarse su propio manual de convivencia, en el que est√° prohibido llevar el pelo largo. T√∫ eres el juez de la tutela: ¬øen qu√© sentido emites tu decisi√≥n?\n",
      "ü§ñ Generando queries con la pregunta del usuario ...\n",
      "üí∞ Conversation price: $436.248323 COP\n",
      "   This message: $4.927544 COP \n",
      "ü§ñ 3 b√∫squedas generadas ...\n",
      "Necesito buscar la definici√≥n y alcance del libre desarrollo de la personalidad en la Constituci√≥n de Colombia para entender los derechos del estudiante.\n",
      "üîé Buscando documentos: libre desarrollo de la personalidad en la Constituci√≥n de Colombia ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 44 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "Debo investigar si las instituciones privadas en Colombia tienen el derecho de admisi√≥n y si este derecho puede limitar el libre desarrollo de la personalidad de los estudiantes.\n",
      "üîé Buscando documentos: derecho de admisi√≥n en instituciones privadas en Colombia ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 37 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "Necesito saber si los manuales de convivencia en instituciones educativas privadas en Colombia pueden establecer normas que limiten el libre desarrollo de la personalidad de los estudiantes y si estas normas son constitucionales.\n",
      "üîé Buscando documentos: manual de convivencia en instituciones educativas privadas en Colombia ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 44 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "ü§ñ Generando nuevas b√∫squedas con la nueva informaci√≥n ...\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j85f9s7yfkrvaszq50j89nn0` on tokens per minute (TPM): Limit 20000, Used 0, Requested 40808. Please try again in 1m2.424s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTienes el siguiente caso: Un estudiante de sexto de bachillerato de un colegio privado cat√≥lico es echado del colegio por tener el pelo largo. √âl laega que en el libre desarrollo de su personalidad, puede llevar el pelo como quiera. Por eso, present√≥ una tutela para que lo reintegren al colegio. El colegio ha contestado a la tutela indicando que, al ser una instituci√≥n privada, ellos pueden reservarse el derecho de admisi√≥n y dictarse su propio manual de convivencia, en el que est√° prohibido llevar el pelo largo. T√∫ eres el juez de la tutela: ¬øen qu√© sentido emites tu decisi√≥n?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[105], line 3\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_conversation\u001b[39m(user_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_prompt:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mget_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[105], line 77\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m     71\u001b[0m query_messages \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     72\u001b[0m     reasoning_results_prompt_message,\n\u001b[1;32m     73\u001b[0m     reasoning_prompt_message,\n\u001b[1;32m     74\u001b[0m ]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mü§ñ Generando nuevas b√∫squedas con la nueva informaci√≥n ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m second_query_completion \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m second_search_terms \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\n\u001b[1;32m     79\u001b[0m     second_query_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     80\u001b[0m )\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mü§ñ \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(second_search_terms)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m b√∫squedas generadas ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[100], line 45\u001b[0m, in \u001b[0;36mgenerate_query\u001b[0;34m(query_messages)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_query\u001b[39m(query_messages):\n\u001b[1;32m     44\u001b[0m     log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(query_messages,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama-3.1-70b-versatile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     log(response)\n\u001b[1;32m     52\u001b[0m     get_conversation_price(response, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3-70b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py:287\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/_base_client.py:1244\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1232\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1240\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1241\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1242\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/_base_client.py:1039\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1038\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1039\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1042\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1043\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1048\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j85f9s7yfkrvaszq50j89nn0` on tokens per minute (TPM): Limit 20000, Used 0, Requested 40808. Please try again in 1m2.424s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "run_conversation(\n",
    "    \"Tienes el siguiente caso: Un estudiante de sexto de bachillerato de un colegio privado cat√≥lico es echado del colegio por tener el pelo largo. √âl laega que en el libre desarrollo de su personalidad, puede llevar el pelo como quiera. Por eso, present√≥ una tutela para que lo reintegren al colegio. El colegio ha contestado a la tutela indicando que, al ser una instituci√≥n privada, ellos pueden reservarse el derecho de admisi√≥n y dictarse su propio manual de convivencia, en el que est√° prohibido llevar el pelo largo. T√∫ eres el juez de la tutela: ¬øen qu√© sentido emites tu decisi√≥n?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üôé‚Äç‚ôÇÔ∏è User: ¬øCu√°les son las principales sentencias de la Corte Constitucional sobre el aborto?\n",
      "ü§ñ Generando queries con la pregunta del usuario ...\n",
      "üí∞ Conversation price: $278.58392999999995 COP (In: 428534, Out: 6112, Total token: 434646)\n",
      "   This message: $1.2386100000000002 COP (In: 1442, Out: 143, Total token: 1585) \n",
      "ü§ñ 3 b√∫squedas generadas ...\n",
      "Necesito buscar las sentencias m√°s relevantes de la Corte Constitucional sobre el aborto para proporcionar un resumen de las decisiones y su impacto en la legislaci√≥n y derechos en Colombia.\n",
      "üîé Buscando documentos: principales sentencias Corte Constitucional aborto ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 50 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "Es importante encontrar documentos que contengan jurisprudencia espec√≠fica de la Corte Constitucional relacionada con el aborto, para entender el contexto legal y las interpretaciones que se han dado.\n",
      "üîé Buscando documentos: Corte Constitucional aborto jurisprudencia ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 42 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "Quiero investigar c√≥mo la Corte Constitucional ha vinculado el aborto con los derechos fundamentales, lo que puede ayudar a entender la base legal de sus sentencias.\n",
      "üîé Buscando documentos: aborto derechos fundamentales Corte Constitucional ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 50 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "ü§ñ Generando nuevas b√∫squedas con la nueva informaci√≥n ...\n",
      "üí∞ Conversation price: $301.87213499999996 COP (In: 465661, Out: 6297, Total token: 471958)\n",
      "   This message: $23.288204999999998 COP (In: 37127, Out: 185, Total token: 37312) \n",
      "ü§ñ 3 b√∫squedas generadas ...\n",
      "Buscando 'principales sentencias Corte Constitucional aborto': Esta b√∫squeda se centra en identificar las sentencias m√°s relevantes de la Corte Constitucional sobre el aborto, lo que permitir√° obtener un resumen claro de las decisiones que han marcado la jurisprudencia en este tema.\n",
      "üîé Buscando documentos: principales sentencias Corte Constitucional aborto ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 50 ...\n",
      "Buscando 'C-355 de 2006 Corte Constitucional aborto': La sentencia C-355 de 2006 es fundamental en la regulaci√≥n del aborto en Colombia, ya que establece las causales en las que no se incurre en delito. Buscar informaci√≥n espec√≠fica sobre esta sentencia ayudar√° a entender su impacto y relevancia.\n",
      "üîé Buscando documentos: C-355 de 2006 Corte Constitucional aborto ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 48 ...\n",
      "Buscando 'jurisprudencia Corte Constitucional aborto derechos fundamentales': Esta b√∫squeda se enfoca en c√≥mo la Corte Constitucional ha vinculado el aborto con los derechos fundamentales, lo que es crucial para comprender el contexto legal y los principios que sustentan las decisiones sobre el aborto en Colombia.\n",
      "üîé Buscando documentos: jurisprudencia Corte Constitucional aborto derechos fundamentales ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 49 ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 150 pasaron 103 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 103 fuentes agregadas ...\n",
      "ü§ñ Escogiendo las mejores fuentes para responder al usuario ...\n",
      "üí∞ Conversation price: $334.54155 COP (In: 516594, Out: 6844, Total token: 523438)\n",
      "   This message: $32.669415 COP (In: 50933, Out: 547, Total token: 51480) \n",
      "1.[20240813222906ccc3552006pdf_chunk579]: La sentencia C-355 de 2006 es fundamental ya que establece las causales en las que el aborto no es considerado un delito, marcando un hito en la jurisprudencia colombiana sobre el aborto.\n",
      "2.[20240820161257ccc7542015pdf_chunk189]: Esta fuente proporciona un resumen de la sentencia C-355 de 2006, explicando su impacto en la despenalizaci√≥n del aborto en Colombia y su relaci√≥n con los derechos fundamentales de las mujeres.\n",
      "3.[20240820201908cct3012016pdf_chunk91]: La sentencia T-301 de 2016 reitera y explica las reglas de la sentencia C-355 de 2006, analizando casos espec√≠ficos y reafirmando el derecho al aborto en las causales establecidas.\n",
      "4.[20240820213515cct6972016pdf_chunk59]: La sentencia T-697 de 2016 aborda la importancia de la sentencia C-355 de 2006 y su aplicaci√≥n en casos de aborto, lo que ayuda a entender la evoluci√≥n de la jurisprudencia en este tema.\n",
      "5.[20240814120246cct9462008pdf_chunk35]: La sentencia T-946 de 2008 analiza la objeci√≥n de conciencia en el contexto del aborto, lo que es relevante para entender las implicaciones legales y √©ticas en la pr√°ctica del aborto en Colombia.\n",
      "6.[20240823072132ccc0552022pdf_chunk297]: La sentencia C-055 de 2022 discute la evoluci√≥n de la jurisprudencia sobre el aborto y su relaci√≥n con los derechos humanos, lo que proporciona un contexto actual sobre el tema.\n",
      "7.[20240823072132ccc0552022pdf_chunk69]: Esta fuente ofrece un an√°lisis de la jurisprudencia reciente sobre el aborto, lo que es crucial para entender c√≥mo se ha desarrollado la interpretaci√≥n legal en Colombia.\n",
      "8.[20240823072132ccc0552022pdf_chunk124]: La sentencia C-055 de 2022 tambi√©n aborda la despenalizaci√≥n del aborto y su relaci√≥n con los derechos fundamentales, lo que es esencial para comprender el marco legal actual.\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 5 fuentes agregadas ...\n",
      "üí∞ Conversation price: $11124.7965 COP (In: 520026, Out: 7549, Total token: 527575)\n",
      "   This message: $113.71350000000001 COP (In: 3432, Out: 705, Total token: 4137) \n",
      "<p>Las principales sentencias de la Corte Constitucional de Colombia sobre el aborto son las siguientes:</p>\n",
      "\n",
      "<h2>Sentencia C-355 de 2006</h2>\n",
      "<p>Esta sentencia es fundamental ya que establece las causales en las que el aborto no es considerado un delito en Colombia. La Corte Constitucional determin√≥ que la prohibici√≥n total del aborto era inconstitucional y estableci√≥ tres causales espec√≠ficas en las que el aborto no ser√≠a penalizado:</p>\n",
      "<ul>\n",
      "  <li>Cuando la continuaci√≥n del embarazo constituya peligro para la vida o la salud de la mujer, certificado por un m√©dico.</li>\n",
      "  <li>Cuando exista grave malformaci√≥n del feto que haga inviable su vida, certificado por un m√©dico.</li>\n",
      "  <li>Cuando el embarazo sea resultado de una conducta constitutiva de acceso carnal o acto sexual sin consentimiento, abusivo, o de inseminaci√≥n artificial o de transferencia de √≥vulo fecundado no consentidas, as√≠ como de incesto, y el hecho punible haya sido debidamente denunciado ante las autoridades competentes.</li>\n",
      "</ul>\n",
      "<p>Esta sentencia marc√≥ un hito en la jurisprudencia colombiana sobre el aborto, al reconocer los derechos fundamentales de las mujeres en estas circunstancias [20240813222906ccc3552006pdf_chunk579] [20240820161257ccc7542015pdf_chunk189] [20240820213515cct6972016pdf_chunk59].</p>\n",
      "\n",
      "<h2>Sentencia T-301 de 2016</h2>\n",
      "<p>Esta sentencia reitera y explica las reglas de la sentencia C-355 de 2006, analizando casos espec√≠ficos y reafirmando el derecho al aborto en las causales establecidas. En particular, se analiz√≥ el caso de una mujer embarazada con una malformaci√≥n √≥sea en el feto, y la Corte Constitucional reafirm√≥ las subreglas constitucionales aplicables al derecho a la interrupci√≥n voluntaria del embarazo [20240820201908cct3012016pdf_chunk91].</p>\n",
      "\n",
      "<h2>Sentencia T-697 de 2016</h2>\n",
      "<p>Esta sentencia aborda la importancia de la sentencia C-355 de 2006 y su aplicaci√≥n en casos de aborto, ayudando a entender la evoluci√≥n de la jurisprudencia en este tema. La Corte record√≥ que una prohibici√≥n total del aborto resultaba inconstitucional y que deb√≠a haber un ejercicio de ponderaci√≥n que equilibrara el deber del Estado de proteger la vida del que est√° por nacer con los derechos fundamentales de la mujer [20240820213515cct6972016pdf_chunk59].</p>\n",
      "\n",
      "<h2>Sentencia T-946 de 2008</h2>\n",
      "<p>Esta sentencia analiza la objeci√≥n de conciencia en el contexto del aborto, lo que es relevante para entender las implicaciones legales y √©ticas en la pr√°ctica del aborto en Colombia. La Corte reafirm√≥ las causales establecidas en la sentencia C-355 de 2006 y destac√≥ la importancia de analizar cada caso en concreto [20240814120246cct9462008pdf_chunk35].</p>\n",
      "\n",
      "<p>Estas sentencias han sido fundamentales para la regulaci√≥n del aborto en Colombia, estableciendo un marco legal que protege los derechos de las mujeres en situaciones espec√≠ficas y garantizando su acceso a la interrupci√≥n voluntaria del embarazo bajo ciertas condiciones.</p>\n",
      "\n",
      "\n",
      "<p>1. CC - C355-2006 - P√°gina 399<br>\n",
      "2. CC - C754-2015 - P√°gina 95<br>\n",
      "3. CC - T301-2016 - P√°gina 50<br>\n",
      "4. CC - T697-2016 - P√°gina 32<br>\n",
      "5. CC - T946-2008 - P√°gina 22<br>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\n",
    "    \"¬øCu√°les son las principales sentencias de la Corte Constitucional sobre el aborto?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üôé‚Äç‚ôÇÔ∏è User: ¬øEn qu√© casos la jurisprudencia ha reconocido la dosis de aprovisionamiento?\n",
      "ü§ñ Generando queries con la pregunta del usuario ...\n",
      "üí∞ Conversation price: $339.67434 COP (In: 521468, Out: 7712, Total token: 529180)\n",
      "   This message: $1.28781 COP (In: 1442, Out: 163, Total token: 1605) \n",
      "ü§ñ 3 b√∫squedas generadas ...\n",
      "Necesito buscar informaci√≥n sobre la jurisprudencia que ha reconocido la dosis de aprovisionamiento, para entender en qu√© casos se ha aplicado y cu√°les son los criterios utilizados por los tribunales.\n",
      "üîé Buscando documentos: dosis de aprovisionamiento jurisprudencia ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 32 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "Es importante identificar casos espec√≠ficos en los que se ha discutido la dosis de aprovisionamiento en la jurisprudencia, para tener ejemplos concretos y entender su aplicaci√≥n pr√°ctica.\n",
      "üîé Buscando documentos: casos jurisprudencia dosis de aprovisionamiento ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 35 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "Adem√°s de la jurisprudencia, es relevante buscar el concepto legal de dosis de aprovisionamiento para tener una base te√≥rica que complemente la informaci√≥n sobre los casos y su reconocimiento en la jurisprudencia.\n",
      "üîé Buscando documentos: dosis de aprovisionamiento concepto legal ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 33 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 25 fuentes agregadas ...\n",
      "ü§ñ Generando nuevas b√∫squedas con la nueva informaci√≥n ...\n",
      "üí∞ Conversation price: $364.37397 COP (In: 560850, Out: 7907, Total token: 568757)\n",
      "   This message: $24.69963 COP (In: 39382, Out: 195, Total token: 39577) \n",
      "ü§ñ 3 b√∫squedas generadas ...\n",
      "Buscando 'casos jurisprudencia dosis de aprovisionamiento Colombia': Esta b√∫squeda se centra en encontrar casos espec√≠ficos en los que la jurisprudencia colombiana ha reconocido la dosis de aprovisionamiento, lo que permitir√° obtener ejemplos concretos y entender c√≥mo se aplica este concepto en la pr√°ctica judicial.\n",
      "üîé Buscando documentos: casos jurisprudencia dosis de aprovisionamiento Colombia ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 37 ...\n",
      "Buscando 'dosis de aprovisionamiento concepto legal Colombia': Es importante entender el concepto legal de dosis de aprovisionamiento en el contexto colombiano, ya que esto proporcionar√° una base te√≥rica que complemente la informaci√≥n sobre los casos y su reconocimiento en la jurisprudencia.\n",
      "üîé Buscando documentos: dosis de aprovisionamiento concepto legal Colombia ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 41 ...\n",
      "Buscando 'jurisprudencia sobre consumo personal y aprovisionamiento estupefacientes': Esta b√∫squeda se enfocar√° en la jurisprudencia relacionada con el consumo personal y la dosis de aprovisionamiento de estupefacientes, lo que ayudar√° a identificar criterios y principios que los tribunales han utilizado para tomar decisiones en estos casos.\n",
      "üîé Buscando documentos: jurisprudencia sobre consumo personal y aprovisionamiento estupefacientes ...\n",
      "üìã Agarrando todos los resultados ...\n",
      "üìã Formateando resultados ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 50 pasaron 44 ...\n",
      "üßπ Eliminando fuentes irrelevantes o duplicadas ...\n",
      "üßπ Docs filtrados. De 150 pasaron 120 ...\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 120 fuentes agregadas ...\n",
      "ü§ñ Escogiendo las mejores fuentes para responder al usuario ...\n",
      "üí∞ Conversation price: $402.951075 COP (In: 621869, Out: 8334, Total token: 630203)\n",
      "   This message: $38.577104999999996 COP (In: 61019, Out: 427, Total token: 61446) \n",
      "1.[20240825154143csjstp5128202258665pdf_chunk18]: Esta fuente es de la Corte Suprema de Justicia y aborda directamente el concepto de dosis de aprovisionamiento, explicando su relaci√≥n con el consumo personal y la no punibilidad de ciertas conductas.\n",
      "2.[20240825140531csjsp2989812112008pdf_chunk12]: Este extracto de la Corte Suprema de Justicia proporciona un contexto hist√≥rico y legal sobre la dosis de aprovisionamiento, adem√°s de mencionar la evoluci√≥n de la jurisprudencia en relaci√≥n con el consumo de estupefacientes.\n",
      "3.[20240825101013csjsp2695202155922pdf_chunk12]: Esta fuente tambi√©n es de la Corte Suprema de Justicia y establece criterios sobre la finalidad del porte de estupefacientes, diferenciando entre consumo personal y tr√°fico, lo que es crucial para entender la jurisprudencia sobre la dosis de aprovisionamiento.\n",
      "4.[20240824123644csjap2581201748005pdf_chunk20]: Este extracto de la Corte Suprema de Justicia discute la antijuridicidad de la conducta de portar estupefacientes en cantidades ligeramente superiores a la dosis personal, lo que es relevante para la pregunta sobre la dosis de aprovisionamiento.\n",
      "5.[20240820213719tsdjmanizalessp20170018301pdf_chunk14]: Este extracto del Tribunal de Manizales proporciona un an√°lisis sobre el porte de estupefacientes y su relaci√≥n con el consumo personal, lo que ayuda a entender c√≥mo se aplica la jurisprudencia en casos espec√≠ficos.\n",
      "üìã Agregando fuentes al contexto ...\n",
      "üìã 5 fuentes agregadas ...\n",
      "üí∞ Conversation price: $13381.785 COP (In: 625440, Out: 9110, Total token: 634550)\n",
      "   This message: $120.92950000000002 COP (In: 3571, Out: 776, Total token: 4347) \n",
      "<p>La jurisprudencia colombiana ha reconocido la figura de la \"dosis de aprovisionamiento\" en varios casos, principalmente diferenciando entre el consumo personal y el tr√°fico de estupefacientes. A continuaci√≥n, se presentan algunos ejemplos relevantes:</p>\n",
      "\n",
      "<p><strong>1. Corte Suprema de Justicia - STP5128-2022:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia explic√≥ que la \"dosis de aprovisionamiento\" se refiere a la cantidad de droga que una persona porta para consumir en varias oportunidades, no necesariamente en una sola ocasi√≥n. La Corte se√±al√≥ que, en algunos casos, las personas pueden portar cantidades ligeramente superiores a la dosis personal permitida sin que esto implique una conducta lesiva del bien jur√≠dico protegido, siempre y cuando se pueda demostrar que el porte est√° asociado al consumo personal y no al tr√°fico. La Corte tambi√©n mencion√≥ que cuando el exceso de la dosis personal es m√≠nimo, se opera una presunci√≥n legal de antijuridicidad que admite prueba en contrario [20240825154143csjstp5128202258665pdf_chunk18].</p>\n",
      "\n",
      "<p><strong>2. Corte Suprema de Justicia - SP29898-2008:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia hizo referencia a la evoluci√≥n hist√≥rica y legal del concepto de \"dosis de aprovisionamiento\". La Corte mencion√≥ que, en el pasado, se consideraba una contravenci√≥n penal portar una dosis personal con el exclusivo prop√≥sito de consumo personal. Sin embargo, esta contravenci√≥n fue declarada inexequible por la Corte Constitucional, que argument√≥ que un Estado respetuoso de la dignidad humana no puede sustituir la educaci√≥n por la represi√≥n como forma de controlar el consumo de sustancias [20240825140531csjsp2989812112008pdf_chunk12].</p>\n",
      "\n",
      "<p><strong>3. Corte Suprema de Justicia - SP2695-2021:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia estableci√≥ que la tipicidad de portar estupefacientes est√° supeditada a la finalidad del agente. Si la conducta persigue el aprovisionamiento para el consumo personal, no debe ser objeto de sanciones jur√≠dico-penales. La Corte subray√≥ que el consumidor de estupefacientes, especialmente si es adicto, debe ser tratado como un sujeto de especial protecci√≥n y destinatario de medidas administrativas de orden pedag√≥gico, terap√©utico y profil√°ctico [20240825101013csjsp2695202155922pdf_chunk12].</p>\n",
      "\n",
      "<p><strong>4. Corte Suprema de Justicia - AP2581-2017:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia precis√≥ que, a pesar de la reforma constitucional y la modificaci√≥n del art√≠culo 376 del C√≥digo Penal, es posible considerar impunes las conductas dirigidas al consumo de estupefacientes en las dosis fijadas por la ley. La Corte reiter√≥ que el porte de cantidades insignificantes o no desproporcionadas destinadas exclusivamente al consumo propio no incide sobre las categor√≠as jur√≠dicas que el legislador pretende proteger [20240824123644csjap2581201748005pdf_chunk20].</p>\n",
      "\n",
      "<p>En resumen, la jurisprudencia colombiana ha reconocido la \"dosis de aprovisionamiento\" en varios casos, destacando la importancia de diferenciar entre el consumo personal y el tr√°fico de estupefacientes. La Corte Suprema de Justicia ha enfatizado que el porte de estupefacientes con fines de consumo personal, incluso en cantidades ligeramente superiores a la dosis personal permitida, no debe ser objeto de sanciones penales, siempre y cuando se pueda demostrar que la finalidad es el consumo y no el tr√°fico.</p>\n",
      "\n",
      "\n",
      "<p>1. CSJ - STP5128-2022(58665) - P√°gina 18<br>\n",
      "2. CSJ - SP29898(12-11-2008) - P√°gina 12<br>\n",
      "3. CSJ - SP2695-2021(55922) - P√°gina 12<br>\n",
      "4. CSJ - AP2581-2017(48005) - P√°gina 17<br>\n",
      "5. TSDJ Manizales - SP2017-00183-01 - P√°gina 13<br>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"¬øQu√© dice el art√≠culo 103 del c√≥digo penal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_conversation(\"¬øCu√°ndo se consuma el hurto?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

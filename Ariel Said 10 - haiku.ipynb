{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import re\n",
    "from datetime import datetime\n",
    "\n",
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "from openai import OpenAI\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from azure.search.documents.models import QueryType\n",
    "from azure.search.documents._generated.models import QueryCaptionResult\n",
    "\n",
    "from openai import AzureOpenAI\n",
    "import tiktoken\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "from groq import Groq\n",
    "from anthropic import Anthropic\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "def num_tokens_from_string(string: str, encoding_name: str = \"cl100k_base\") -> int:\n",
    "    \"\"\"Returns the number of tokens in a text string.\"\"\"\n",
    "    encoding = tiktoken.get_encoding(encoding_name)\n",
    "    num_tokens = len(encoding.encode(string))\n",
    "    return num_tokens\n",
    "\n",
    "class AzureEmbeddings:\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def get_embedding():\n",
    "        return AzureOpenAIEmbeddings(\n",
    "            azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "            openai_api_version=\"2023-08-01-preview\",\n",
    "            openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_URL\")\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_embeddings(content: str):\n",
    "        embeddings = AzureOpenAIEmbeddings(\n",
    "            azure_deployment=os.getenv(\"AZURE_OPENAI_DEPLOYMENT\"), \n",
    "            openai_api_version=\"2023-08-01-preview\",\n",
    "            openai_api_key=os.getenv(\"AZURE_OPENAI_API_KEY\"),\n",
    "            azure_endpoint=os.getenv(\"AZURE_OPENAI_URL\")\n",
    "        )\n",
    "\n",
    "        doc_result = embeddings.embed_documents([content])\n",
    "\n",
    "        return doc_result[0]\n",
    "\n",
    "# openai_client = AzureOpenAI(\n",
    "#     api_key=os.getenv(\"AZURE_CHAT_OPENAI_API_KEY\"), \n",
    "#     api_version=os.getenv(\"AZURE_CHAT_OPENAI_API_VERSION\"), \n",
    "#     azure_endpoint=os.getenv(\"AZURE_CHAT_OPENAI_ENDPOINT\")\n",
    "#     )\n",
    "openai_client = OpenAI(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    "    )\n",
    "groq_client = Anthropic(\n",
    "    api_key=os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "embeddings_client = AzureEmbeddings()\n",
    "store_search_url: str = f'https://{os.getenv('AZURE_COGNITIVE_SEARCH_SERVICE_NAME')}.search.windows.net'\n",
    "search_client = SearchClient(\n",
    "            store_search_url, os.getenv(\"AZURE_COGNITIVE_SEARCH_INDEX_NAME\"),\n",
    "            AzureKeyCredential(os.getenv(\"AZURE_COGNITIVE_SEARCH_API_KEY\"))\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file_name = \"\"\n",
    "\n",
    "\n",
    "def ensure_directory(directory_name):\n",
    "    if not os.path.exists(directory_name):\n",
    "        os.makedirs(directory_name)\n",
    "\n",
    "\n",
    "def log(message):\n",
    "    global log_file_name\n",
    "    ensure_directory(\"logs\")\n",
    "    with open(log_file_name, \"a\") as file:\n",
    "        file.write(f\"{datetime.now()}\\n{message}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "conversation_price = 0\n",
    "conversation_ct = 0\n",
    "conversation_pt = 0\n",
    "conversation_tt = 0\n",
    "\n",
    "\n",
    "def get_conversation_price(new_completion, model=\"gpt4o\"):\n",
    "    global conversation_price, conversation_ct, conversation_pt, conversation_tt\n",
    "    USD_price_in_COP = 4100\n",
    "\n",
    "    if model == \"gpt4o-mini\":\n",
    "        in_price = 0.0000006\n",
    "        out_price = 0.00000015\n",
    "    if model == \"gpt4o\":\n",
    "        in_price = 0.000015\n",
    "        out_price = 0.000005\n",
    "    if model == \"llama-3-8b\":\n",
    "        in_price = 0.00000005\n",
    "        out_price = 0.00000008\n",
    "    if model == \"llama-3-70b\":\n",
    "        in_price = 0.00000059\n",
    "        out_price = 0.0000007\n",
    "    if model == \"haiku\":\n",
    "        in_price = 0.00000025\n",
    "        out_price = 0.00000125\n",
    "\n",
    "    ct = new_completion.usage.completion_tokens\n",
    "    pt = new_completion.usage.prompt_tokens\n",
    "    tt = new_completion.usage.total_tokens\n",
    "    usd_total_price = (ct * out_price) + (pt * in_price)\n",
    "    cop_total_price = usd_total_price * USD_price_in_COP\n",
    "    conversation_price += cop_total_price\n",
    "    # conversation_ct += ct\n",
    "    # conversation_pt += pt\n",
    "    # conversation_tt += tt\n",
    "    # conversation_usd_total_price = (conversation_ct * out_price) + (\n",
    "    #     conversation_pt * in_price\n",
    "    # )\n",
    "    # conversation_cop_total_price = conversation_usd_total_price * USD_price_in_COP\n",
    "\n",
    "    print(\n",
    "        f\"💰 Conversation price: ${conversation_price} COP\\n\"\n",
    "        f\"   This message: ${cop_total_price} COP \"\n",
    "        f\"\"\n",
    "    )\n",
    "    log(\n",
    "        f\"💰 Conversation price: ${conversation_price} COP\\n\"\n",
    "        f\"   This message: ${cop_total_price} COP \"\n",
    "        f\"\"\n",
    "    )\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 🔑 Definir system prompt y tools\n",
    "\n",
    "messages = []\n",
    "conversation = []\n",
    "user_input = \"\"\n",
    "\n",
    "codes_to_laws = \"\"\"\n",
    "- Código Penal: Ley 599 de 2000\n",
    "- Código Civil: Ley 57 de 1887\n",
    "- Código de Comercio: Decreto 410 de 1971\n",
    "- Código de Procedimiento Civil: Decreto 1400 de 1970\n",
    "- Código de Procedimiento Penal: Ley 906 de 2004\n",
    "- Código General del Proceso: Ley 1564 de 2012\n",
    "- Código de la Infancia y la Adolescencia: Ley 1098 de 2006\n",
    "- Código Nacional de Policía: Decreto 1355 de 1970\n",
    "- Código de Recursos Naturales: Decreto 2811 de 1974\n",
    "- Código Electoral: Decreto 2241 de 1986\n",
    "- Código Disciplinario Único: Ley 734 de 2002\n",
    "- Código Contencioso Administrativo: Ley 1437 de 2011 (anteriormente Decreto 1 de 1984)\n",
    "- Código de Minas: Ley 685 de 2001\n",
    "- Código de Educación: Ley 115 de 1994\n",
    "- Código Nacional de Tránsito Terrestre: Ley 769 de 2002\n",
    "- Código del Menor: Decreto 2737 de 1989\n",
    "- Código de Construcción del Distrito Capital de Bogotá: Acuerdo 20 de 1995\n",
    "- Código de Construcción Sismo-Resistente: Acuerdo correspondiente (no especificado en los resultados)\n",
    "- Código de Régimen Departamental: Decreto 1222 de 1986\n",
    "- Código de Régimen Político y Municipal: Decreto-Ley 1333 de 1986\n",
    "- Código Penal Militar: Ley 522 de 1999\n",
    "- Código Penitenciario y Carcelario: Ley 65 de 1993\n",
    "- Código Procesal del Trabajo y del Seguro Social: Decreto-Ley 2158 de 1948\n",
    "- Código Sustantivo del Trabajo: Decreto 2663 de 1950\n",
    "- Código Sanitario Nacional: Ley 9 de 1979\n",
    "- Código General Disciplinario: Ley 1952 de 2019\n",
    "- Código Nacional de Seguridad y Convivencia Ciudadana: Ley 1801 de 2016\n",
    "- CODIGO DE POLICIA DE BOGOTA: ACUERDO 79 DE 2003\n",
    "- Código Penal Militar: Ley 522 de 1999\n",
    "- Código Penitenciario y Carcelario: Ley 65 de 1993\n",
    "- Código Procesal del Trabajo y del Seguro Social: Decreto-Ley 2158 de 1948\n",
    "- Código Sustantivo del Trabajo: Decreto 2663 de 1950\n",
    "- Código Sanitario Nacional: Ley 9 de 1979\n",
    "- Código General Disciplinario: Ley 1952 de 2019\n",
    "- Código Nacional de Seguridad y Convivencia Ciudadana: Ley 1801 de 2016\"\"\"\n",
    "\n",
    "\n",
    "get_next_chunk = {\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"get_next_chunk\",\n",
    "        \"description\": \"Use this tool to get when an important sources comes incomplete or the content is cut off. This tool will help you retrieve the following section of that given source.\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"source_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"the unique identifier of the chunk that is incomplete. eg:'20240719192458csjscpboletinjurisprudencial20181219pdf_chunk30'\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"source_id\"],\n",
    "        },\n",
    "    },\n",
    "}\n",
    "\n",
    "response_system_template = f\"\"\"\n",
    "Eres Ariel, un asistente de investigación legal en jurisprudencia colombiana. Sigue estas instrucciones al responder:\n",
    "\n",
    "1. Consulta de Fuentes:\n",
    "- Tienes acceso a algunas fuentes que previamente has encontrado y seleccionado para generar esta respuesta. - Dentro de esas fuentes se encuentra toda la información disponible para responder. \n",
    "- Expresa toda la información que encuentres en las fuentes proporcionadas y que sea relevante para responder.\n",
    "- Si las fuentes no ayudan a responder la pregunta, responde: \"No encuentro información con esos términos, ¿puedes reformular tu consulta?\"\n",
    "\n",
    "2. Redacción de Respuestas:\n",
    "- Sé detallado y preciso, utilizando exclusivamente la información de las fuentes proporcionadas.\n",
    "- No incluyas información que no haya sido extraída directamente de las fuentes. Está prohibido.\n",
    "- No inventes información por ningún motivo. No alucines.\n",
    "\n",
    "3. Citación de Fuentes:\n",
    "- Cita el mayor número de fuentes aplicables.\n",
    "- Utiliza corchetes para referenciar la fuente con el ID del fragmento sin modificarlo, por ejemplo: [12345_id_de_ejemplo].\n",
    "- No combines fuentes; lista cada fuente por separado.\n",
    "\n",
    "3. Formato de Respuesta:\n",
    "- Escribe tus respuestas en formato HTML, sin incluir los tags \"```html\" al principio o al final.\n",
    "- Utiliza etiquetas HTML estándar como <p>, <strong>, <em>, etc.\n",
    "\n",
    "5. Interpretación de Categorías:\n",
    "- Prioriza las fuentes según su categoría:\n",
    "    1. Constitucional: Es la norma máxima y más importante establecida por el gobierno del país. \n",
    "    2. Legal: Es la que le sigue en importancia y son las leyes dictadas por el Congreso. \n",
    "    3. Infralegal: Le sigue en importancia a la categoría Legal y comprende decretos, resoluciones y otros documentos oficiales de autoridades públicas como ministerios y superintendencias. \n",
    "    4. Jurisprudencia: Están por debajo de las leyes y las normas infralegales. Son proferidas por jueces de la república y demuestran cómo se ha ejercido la ley en el pasado. Las sentencias y autos de la Corte Constitucional están por encima de la ley,\n",
    "    5. Doctrina: Son documentos o libros escritos por autores del derecho que no son parte de la ley pero ayudan a darle una interpetación a la ley.\n",
    "- Da mayor importancia a las fuentes más actuales.\n",
    "\n",
    "6. Precisión Legal:\n",
    "- Siempre dale más importancia a la fuente primaria. Si debes citar una ley, artículo o norma, cita la fuente directa, es decir, esa ley, artículo o normal.\n",
    "- Las fuentes secundarias te ayudarán a entender la interpretación sobre las fuentes primarias.\n",
    "- No confundas leyes o artículos; si el usuario pregunta por una ley específica, ignora extractos de otras leyes.\n",
    "- Utiliza las fuentes para dar una respuesta completa y darle al usuario información adicional que pueda serle de ayuda.\n",
    "- Cita textualmente cuando necesites mencionar el contenido un artículo, ley u otro documento y si el tamaño de este lo permite.\n",
    "\n",
    "7. Evita Imprecisiones:\n",
    "- En caso de encontrar información contradictoria, señálala y sugiere una posible causa.\n",
    "- No te salgas del tema de la pregunta del usuario.\n",
    "- En caso que el usuario haya dado información incorrecto o imprecisa, señálala y da un argumento.\n",
    "- Si la ley, la jurisprudencia y la doctrina tienen respuestas diferentes o interpretaciones diferentes para la misma pregunta, señala las distintas perspectivas.\n",
    "\"\"\"\n",
    "\n",
    "# Incluir que el usuario puede estar proporcionando alguna información que es falsa, en ese caso debe apuntarla y argumentar con la información de las fuentes el porqué es falsa.\n",
    "# Incluir que señale información contradictoria si es relevante en las fuentes.\n",
    "# Que siempre le dé más importancia a las fuentes primarias.\n",
    "# Que las fuentes secundarias ayudan a dar interpretación y contexto.\n",
    "\n",
    "query_system_template = f\"\"\"Eres un asistente de investigación con el objetivo de buscar en una base de conocimiento legal con cientos de miles de documentos, fuentes confiables y precisas acerca de la pregunta del usuario. La base de conocimientos está alojada en Azure AI Search y debes generar un query por cada búsqueda que necesitas y que que conserve todo el significado semántico de la idea. \n",
    "\n",
    "Los documentos están guardados en fragmentos con los siguientes campos:\n",
    "- id: Identificador único del fragmento\n",
    "- title: Título del documento\n",
    "- author: Autor del documento\n",
    "- keywords: Tema legal, puede ser: General, Constitucional, Internacional_Publico, Internacional_Privado, Penal, Financiero, entre otros.\n",
    "- category: Tipo de documento legal. Las opciones son: Jurisprudencia, Doctrina, Constitucional, Legal, Infralegal y Otros_temas_legales. \n",
    "- page: Página de la que fue extraído el fragmento.\n",
    "- year: Año en el que se publicó el documento.\n",
    "- content: 500 tokens de contenido, fragmento o extracto del documento. Son solo 500 tokens del documento completo.\n",
    "\n",
    "Pasos para generar la búsqueda:\n",
    "1. Identifica qué información necesitas buscar para responder de forma precisa y completa al usuario.\n",
    "2. Solo puedes hacer 3 búsquedas, así que elabora un plan de investigación donde organizarás cómo puedes distribuir tus búsquedas en caso que necesites hacer más de 1.  \n",
    "3. Genera un query por cada búsquedad que necesitas ejecutar. Puedes generar un máximo de 3 búsquedas. Puedes buscar cualquier cosa, desde teorías del derecho, hasta leyes o una búsqueda general.\n",
    "4. Cada búsqueda solo puede contener 1 idea. Eso significa que si debes comparar teorías, definiciones, conceptos, leyes, artículos o documentos, debes buscarlos por separado.\n",
    "5. Por cada búsqueda, da una breve explicación donde argumentes por qué necesitas hacer esa búsqueda.\n",
    "\n",
    "Cada query debe cumplir con las siguientes checklist:\n",
    "[] Debe ser una idea semánticamente completa.\n",
    "[] Debe contener palabras clave. Por ejemplo: conceptos, teorías, artículos, leyes, normas, títulos de documento, o palabras contextuales como 'cuándo', 'dónde', 'lugar', 'momento', 'tiempo', etc.\n",
    "[] Debe ser conciso y preciso. No debe ser demasiado largo. \n",
    "\n",
    "Recomendaciones adicionales:\n",
    "- No todos los query deben ser específicos para un documento, recuerda que solo puedes hacer máximo 3 búsquedas, así que en ocasiones puedes obtener mejor información si buscas conceptos más generales en vez de un documento específico.\n",
    "- El query puede ser a forma de pregunta.\n",
    "\n",
    "Ejemplos de buenos query:\n",
    "1. Pregunta: '¿Cuándo se entiende por terminada una condena?' - Query: '¿cuándo termina una condena?'\n",
    "2. Pregunta: '¿Qué dice el artículo 223 del código penal?' - Query: 'artículo 223 Código Penal Ley 599 de 2000 '\n",
    "3. Pregunta: '¿En qué artículo de la Constitución se consagra el bloque de constitucionalidad?' - Query: 'bloque de constitucionalidad Constitución'\n",
    "4. Pregunta: '¿Cuándo se consuma el hurto?' - Query: '¿cuándo se consuma el hurto?'\n",
    "\n",
    "Esta es una lista de los códigos en colombia y sus respectiva ley. Si necesitas buscar alguna de estas fuentes, debes incluir ambas refencias en tu query: {codes_to_laws}\n",
    "\n",
    "Genera tu respuesta en formato JSON Array. Aunque generes solo 1 búsqueda, mete el JSON en un array[] con el siguiente schema:\n",
    "{{\"searches\":[{{\"search_query\":\"El query de búsqueda completo. Este debe cumplir con todos los requitiso.\",\"reason\":\"Argumento de porqué necesitas hacer esta búsqueda.\"}}]}}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "query_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"search_query\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"searches\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"search_query\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"El query de búsqueda completo. Este debe cumplir con todos los requitiso.\",\n",
    "                            },\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Argumento de porqué necesitas hacer esta búsqueda.\",\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"search_query\",\n",
    "                            \"reason\",\n",
    "                        ],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                },\n",
    "                #     \"strategy\": {\n",
    "                #         \"type\": \"string\",\n",
    "                #         \"description\": \"Describe brevemente qué estrategia de investigación vas a ejecutar y porqué.\",\n",
    "                #     },\n",
    "            },\n",
    "            \"required\": [\"searches\"],\n",
    "            # \"required\": [\"searches\", \"strategy\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "selected_sources_schema = {\n",
    "    \"type\": \"json_schema\",\n",
    "    \"json_schema\": {\n",
    "        \"name\": \"selected_sources\",\n",
    "        \"strict\": True,\n",
    "        \"schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"sources\": {\n",
    "                    \"type\": \"array\",\n",
    "                    \"items\": {\n",
    "                        \"type\": \"object\",\n",
    "                        \"properties\": {\n",
    "                            \"source_id\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"ID de la fuente que seleccionaste\",\n",
    "                            },\n",
    "                            \"reason\": {\n",
    "                                \"type\": \"string\",\n",
    "                                \"description\": \"Argumento de porqué seleccionaste esta fuente.\",\n",
    "                            },\n",
    "                        },\n",
    "                        \"required\": [\n",
    "                            \"source_id\",\n",
    "                            \"reason\",\n",
    "                        ],\n",
    "                        \"additionalProperties\": False,\n",
    "                    },\n",
    "                },\n",
    "                \"selection_strategy\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"Describe brevemente porqué seleccionaste de esta manera las fuentes. ¿Cuál fue tu estrategia y porqué no seleccionaste otros documentos?\",\n",
    "                },\n",
    "            },\n",
    "            \"required\": [\"sources\", \"selection_strategy\"],\n",
    "            \"additionalProperties\": False,\n",
    "        },\n",
    "    },\n",
    "}\n",
    "# Agregar un campo para identificar fuentes cortadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_completion(completion_messages):\n",
    "    log(f\"{json.dumps(completion_messages, indent=4)}\\n\")\n",
    "    response = openai_client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=completion_messages,\n",
    "        tools=[get_next_chunk],\n",
    "        temperature=0.2,\n",
    "        n=1,\n",
    "        tool_choice=\"auto\",\n",
    "    )\n",
    "    log(response)\n",
    "    get_conversation_price(response)\n",
    "    return response\n",
    "\n",
    "\n",
    "def choose_sources_completion(completion_messages):\n",
    "    log(f\"{json.dumps(completion_messages, indent=4)}\\n\")\n",
    "    response = groq_client.messages.create(\n",
    "        max_tokens=2000,\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=completion_messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    log(response)\n",
    "    get_conversation_price(response, model=\"haiku\")\n",
    "    return response\n",
    "\n",
    "\n",
    "def generate_query(query_messages):\n",
    "    log(f\"{json.dumps(query_messages, indent=4)}\\n\")\n",
    "    response = groq_client.messages.create(\n",
    "        max_tokens=2000,\n",
    "        model=\"claude-3-haiku-20240307\",\n",
    "        messages=query_messages,\n",
    "        temperature=0.0,\n",
    "    )\n",
    "    log(response)\n",
    "    get_conversation_price(response, model=\"haiku\")\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_search_results(docs_list):\n",
    "    print(f\"📋 Agarrando todos los resultados ...\")\n",
    "    documents = []\n",
    "    try:\n",
    "        docs_list = list(docs_list)\n",
    "        print(f\"📋 Formateando resultados ...\")\n",
    "        for index, document in enumerate(docs_list, start=1):\n",
    "            captions: QueryCaptionResult = document.get(\"@search.captions\", \"\")\n",
    "            captions_text = \" // \".join([caption.text for caption in captions]) if captions is not None else \"\"\n",
    "            doc_formatted = {\n",
    "                \"position\" : index,\n",
    "                \"score\": document.get(\"@search.score\", 10),\n",
    "                \"rerank\": document.get(\"@search.reranker_score\", 10),\n",
    "                \"captions\": captions_text,\n",
    "                \"id\": document[\"id\"],\n",
    "                \"title\": document[\"title\"],\n",
    "                \"author\": document[\"author\"],\n",
    "                \"keywords\": document[\"keywords\"],\n",
    "                \"category\": document[\"category\"],\n",
    "                \"page\": document[\"page\"],\n",
    "                \"year\": document[\"year\"],\n",
    "                \"has_copyright\": document[\"has_copyright\"],\n",
    "                \"file_path\": document[\"file_path\"],\n",
    "                \"external_id\": document[\"external_id\"],\n",
    "                \"content\": document[\"content\"],\n",
    "            }\n",
    "            documents.append(doc_formatted)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    log(\n",
    "        f\">>>>>>format_search_results:\\n\"\n",
    "        f\"{json.dumps(documents, indent=4)}\"\n",
    "        )\n",
    "    return documents\n",
    "\n",
    "def filter_docs(doc_list):\n",
    "    print(f\"🧹 Eliminando fuentes irrelevantes o duplicadas ...\")\n",
    "    filtered_docs = []\n",
    "    seen_docs = set()\n",
    "    \n",
    "    for doc in doc_list:\n",
    "        score = doc.get(\"score\", 10) \n",
    "        rerank = doc.get(\"rerank\", 10) \n",
    "        content = doc[\"content\"] \n",
    "        if (\n",
    "            content not in seen_docs\n",
    "            and (rerank > 2\n",
    "            or score > 0.17)\n",
    "        ):\n",
    "            filtered_docs.append(doc)\n",
    "            seen_docs.add(content)\n",
    "    print(f\"🧹 Docs filtrados. De {len(doc_list)} pasaron {len(filtered_docs)} ...\")\n",
    "    log(f\"🧹 Docs filtrados. De {len(doc_list)} pasaron {len(filtered_docs)} ...\\n\"\n",
    "    f\"{json.dumps(filtered_docs, indent=4)}\")\n",
    "    return filtered_docs\n",
    "\n",
    "def add_doc_to_context(docs_list):\n",
    "    print(f\"📋 Agregando fuentes al contexto ...\")\n",
    "    sources = \"\"\n",
    "    counter = 0\n",
    "    \n",
    "    for document in docs_list:\n",
    "        counter += 1\n",
    "        sources += (\n",
    "            f\"Fuente:\\n\"\n",
    "            f\"{document.get(\"reason\", \"\")}\"\n",
    "            f\"id: {document[\"id\"]}\\n\"\n",
    "            f\"title: {document[\"title\"]}\\n\"\n",
    "            f\"author: {document[\"author\"]}\\n\"\n",
    "            f\"year: {document[\"year\"]}\\n\"\n",
    "            f\"keywords: {document[\"keywords\"]}\\n\"\n",
    "            f\"category: {document[\"category\"]}\\n\"\n",
    "            f\"page: {document[\"page\"]}\\n\"\n",
    "            f\"content: {document[\"content\"]}\\n\"\n",
    "            f\"\\n\\n\"\n",
    "        )      \n",
    "    log(\n",
    "        f\"To add in Context: \\n\"\n",
    "        f\"{json.dumps({\"sources\":sources}, indent=4)}\"\n",
    "        )\n",
    "    print(f\"📋 {counter} fuentes agregadas ...\")\n",
    "    return sources\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_for_chunks(text_query):\n",
    "    log(f\"🔎 Buscando documentos: {text_query} ...\")\n",
    "    print(f\"🔎 Buscando documentos: {text_query} ...\")\n",
    "    results_num = 50\n",
    "    vector_query = embeddings_client.generate_embeddings(content=text_query)\n",
    "\n",
    "    results = search_client.search(\n",
    "        search_text=text_query,\n",
    "        vector_queries=[\n",
    "            {\n",
    "                \"vector\": vector_query,\n",
    "                \"k\": results_num,\n",
    "                \"fields\": \"content_vector\",\n",
    "                \"kind\": \"vector\",\n",
    "                # \"exhaustive\": True,\n",
    "            }\n",
    "        ],\n",
    "        top=results_num,\n",
    "        query_type=QueryType.SEMANTIC,\n",
    "        semantic_configuration_name=\"default\",\n",
    "        query_caption=\"extractive|highlight-false\",\n",
    "        scoring_profile=\"legal\",\n",
    "        scoring_parameters=[\n",
    "            \"tagx6-Constitucional\",\n",
    "            \"tagx5-Legal\",\n",
    "            \"tagx4-Infralegal\",\n",
    "            \"tagx3-Jurisprudencia\",\n",
    "            \"tagx2-Doctrina\",\n",
    "        ],\n",
    "    )\n",
    "    results_formatted = format_search_results(results)\n",
    "    restults_filtered = filter_docs(results_formatted)\n",
    "\n",
    "    return restults_filtered[:25]\n",
    "\n",
    "\n",
    "def get_next_chunks(id):\n",
    "    log(f\"⏩️ Buscando los chunks siguientes de {id} ...\")\n",
    "    print(f\"⏩️ Buscando los chunks siguientes de {id} ...\")\n",
    "    pattern = r\"^(.*_chunk)(\\d+)$\"\n",
    "    match = re.search(pattern, id)\n",
    "\n",
    "    if match:\n",
    "        prefix = match.group(1)\n",
    "        chunk_number = int(match.group(2))\n",
    "        next_chunks_result = search_client.search(\n",
    "            filter=f\"id eq '{prefix}{chunk_number + 1}' or id eq '{prefix}{chunk_number + 2}'\",\n",
    "            top=2,\n",
    "        )\n",
    "        return format_search_results(list(next_chunks_result))\n",
    "\n",
    "\n",
    "def get_next_chunk_tool(source_id):\n",
    "    next_chunks = get_next_chunks(source_id)\n",
    "    log(f\"Continuación de {source_id}:\\n{add_doc_to_context(next_chunks)}\")\n",
    "    return f\"Continuación de {source_id}:\\n{add_doc_to_context(next_chunks)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def append_message(new_message):\n",
    "    global messages, conversation\n",
    "\n",
    "    if isinstance(new_message, dict):\n",
    "        role = new_message.get(\"role\")\n",
    "        content = new_message.get(\"content\")\n",
    "    else:\n",
    "        role = new_message.role\n",
    "        content = new_message.content\n",
    "\n",
    "    if role == \"assistant\":\n",
    "        if new_message.tool_calls:\n",
    "            tool_calls = new_message.tool_calls\n",
    "            tool_calls_formatted = []\n",
    "            for tool_call in tool_calls:\n",
    "                tool_calls_formatted.append(\n",
    "                    {\n",
    "                        \"id\": tool_call.id,\n",
    "                        \"function\": {\n",
    "                            \"arguments\": str(json.loads(tool_call.function.arguments)),\n",
    "                            \"name\": tool_call.function.name,\n",
    "                        },\n",
    "                        \"type\": \"function\",\n",
    "                    }\n",
    "                )\n",
    "            messages.append(\n",
    "                {\n",
    "                    \"role\": \"assistant\",\n",
    "                    \"tool_calls\": tool_calls_formatted,\n",
    "                },\n",
    "            )\n",
    "            return messages  ## Assistant call tools\n",
    "        elif content:\n",
    "            messages.append({\"role\": \"assistant\", \"content\": content})\n",
    "            return messages  ## Assistant talk\n",
    "    elif role == \"tool\":\n",
    "        messages.append(new_message)\n",
    "        return messages  ## Tool reponse\n",
    "    else:\n",
    "        return messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def call_tools(tool_calls):\n",
    "    for tool_call in tool_calls:\n",
    "        tool_name = tool_call.function.name\n",
    "        tool_args = json.loads(tool_call.function.arguments)\n",
    "        if tool_name == \"get_next_chunk\":\n",
    "            content = get_next_chunk_tool(tool_args.get(\"source_id\"))\n",
    "\n",
    "        new_tool_message = {\n",
    "            \"tool_call_id\": tool_call.id,\n",
    "            \"role\": \"tool\",\n",
    "            \"name\": tool_name,\n",
    "            \"content\": content,\n",
    "        }\n",
    "\n",
    "        append_message(new_message=new_tool_message)\n",
    "\n",
    "    print(\">> 🤖 Generando respuesta ...\")\n",
    "    new_assistant_completion = generate_completion()\n",
    "    new_assistant_message = new_assistant_completion.choices[0].message\n",
    "    append_message(new_message=new_assistant_message)\n",
    "\n",
    "    if new_assistant_message.content:\n",
    "        return print(\"💬 Assistant:\" + new_assistant_message.content)\n",
    "    else:\n",
    "        return call_tools(\n",
    "            tool_calls=new_assistant_message.tool_calls,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_conversation(user_prompt=None):\n",
    "    if user_prompt:\n",
    "        get_answer(user_prompt)\n",
    "    else:\n",
    "        while True:\n",
    "            user_input = input(\"You: \")\n",
    "            if user_input.lower() == \"exit\":\n",
    "                print(\"Exiting chat...\")\n",
    "                break\n",
    "            get_answer(user_input)\n",
    "\n",
    "\n",
    "def get_answer(user_prompt):\n",
    "    global messages, log_file_name, user_input\n",
    "\n",
    "    user_input = user_prompt\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%m-%d %H:%M\")\n",
    "    log_file_name = f\"logs/{current_time} - {user_input[:50]}.log\"\n",
    "\n",
    "    print(\"🙎‍♂️ User: \" + user_input)\n",
    "    log(f\"User input: {user_input}\")\n",
    "\n",
    "    query_prompt_message = {\"role\": \"system\", \"content\": query_system_template}\n",
    "    response_prompt_message = {\"role\": \"system\", \"content\": response_system_template}\n",
    "    query_user_prompt_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Genera uno o varias búsquedas para responder esta pregunta: {user_input}\",\n",
    "    }\n",
    "\n",
    "    query_messages = [\n",
    "        query_prompt_message,\n",
    "        *messages,\n",
    "        query_user_prompt_message,\n",
    "    ]\n",
    "\n",
    "    print(\"🤖 Generando queries con la pregunta del usuario ...\")\n",
    "    first_query_completion = generate_query(query_messages)\n",
    "    first_search_terms = json.loads(\n",
    "        first_query_completion.choices[0].message.content\n",
    "    ).get(\"searches\")\n",
    "    print(f\"🤖 {len(first_search_terms)} búsquedas generadas ...\")\n",
    "\n",
    "    sources_found = []\n",
    "    search_result_prompt = \"\"\n",
    "    search_reasons = \"\"\n",
    "\n",
    "    for search in first_search_terms:\n",
    "        search_query = search.get(\"search_query\")\n",
    "        query_reason = search.get(\"reason\")\n",
    "        # print(f\"Buscando '{search_query}': {query_reason}\")\n",
    "        print(query_reason)\n",
    "        query_results = search_for_chunks(search_query)\n",
    "        sources_found += query_results\n",
    "        search_reasons += f\"{query_reason} Por eso buscaré '{search_query}'.\\n\"\n",
    "        # search_queries += f\"'{search_query}',\"\n",
    "        sources_to_add = add_doc_to_context(query_results)\n",
    "        search_result_prompt += f\"{query_reason}.\\nPor eso búsqué '{search_query}' y encontré estas fuentes:\\n{sources_to_add}\\n\\n\"\n",
    "\n",
    "    # Meter aquí razonamiento de qué información ha encontrado en esta búsqueda.\n",
    "\n",
    "    reasoning_results_prompt_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": search_result_prompt,\n",
    "    }\n",
    "    reasoning_prompt_message = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"Necesito que plantees una nueva y mejorada estrategia de búsqueda para responder al usuario de forma completa:\\n1. Resume La Información: Lee y absorbe toda la información de las fuentes y utiliza los hallazgos más relevantes para mi investigación.\\n2. Genera Una Nueva Búsqueda: Con estos nuevos hallazgos sugiere un máximo de 3 búsquedas que ayuden a conseguir información precisa y relevante para reponder a la pregunta del usuario.\\n3. Dime por qué estas 3 nuevas búsquedas me ayudarían en mi investigación.\\nRecuerda que cada query debe cumplir con el checklist y que estamos buscando documentos para responder a: {user_input}\",\n",
    "    }\n",
    "\n",
    "    query_messages += [\n",
    "        reasoning_results_prompt_message,\n",
    "        reasoning_prompt_message,\n",
    "    ]\n",
    "\n",
    "    print(\"🤖 Generando nuevas búsquedas con la nueva información ...\")\n",
    "    second_query_completion = generate_query(query_messages)\n",
    "    second_search_terms = json.loads(\n",
    "        second_query_completion.choices[0].message.content\n",
    "    ).get(\"searches\")\n",
    "    print(f\"🤖 {len(second_search_terms)} búsquedas generadas ...\")\n",
    "\n",
    "    query_reasons = \"\"\n",
    "    # search_strategy = first_search_terms.get(\"strategy\")\n",
    "    # print(f\"{search_strategy}\")\n",
    "    for search in second_search_terms:\n",
    "        search_query = search.get(\"search_query\")\n",
    "        query_reason = search.get(\"reason\", \"\")\n",
    "        print(f\"Buscando '{search_query}': {query_reason}\")\n",
    "        # print(query_reason)\n",
    "        query_results = search_for_chunks(search_query)\n",
    "        sources_found += query_results\n",
    "        query_reasons += f\"{query_reason} Por eso busqué '{search_query}'. \"\n",
    "\n",
    "    # return\n",
    "    sources_found_filtered = filter_docs(sources_found)\n",
    "    sources_to_add = add_doc_to_context(sources_found_filtered)\n",
    "\n",
    "    response_prompt_message = {\"role\": \"system\", \"content\": f\"\"\"{response_system_template}\\n\\nGenera tu respuesta en formato JSON con el siguiente schema:{{\"sources\":[{{\"source_id\":\"ID de la fuente que seleccionaste\"}}]}}\"\"\"}\n",
    "    select_user_prompt_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": f\"Busca información relevante y selecciona las mejores fuentes para responder a: {user_input}\",\n",
    "    }\n",
    "    select_prompt_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"\"\"{query_reasons}.\\n\\nResultados de mis búsquedas:\\n{sources_to_add}\\n\\nEjectuaste una búsqueda con lo que el usuario te preguntó y encontraste fuentes que pueden servirte, ahora debes escoger las mejores. Sigue las siguientes instrucciones:\\n1. Revisa todos los extractos obtenidos con tu búsqueda y selecciona mínimo 3 y máximo 10 fuentes que te sirvan para responder al usuario. No pueden ser menos de 3 y al menos 2 de esas deben ser Jurisprudencia o Doctrina.\\n2. Enlista las fuentes que escogiste e identifícalas por su ID y por ningún motivo en absoluto cambies el valor del ID o número de chunk de una fuente. Ordénalas por importancia, posicionando de primero la que consideres más relevante o más cercanas a lo que el usuario pidió.\\n3.(Opcional) Intenta seleccionar un grupo de fuentes donde puedas dar una respuesta completa a la pregunta, señalar contradicciones en las fuentes, dar información complementaria relevante y señalar diversos puntos de vista al respecto lo que el usuario pregunta.\\n4. Al lado de cada fuente que seleccionaste escribe una muy breve explicación argumentando porqué la escogiste y porqué ayuda a responder mejor la solicitud del usuario.\\n5. Toda la información debe provenir de lo que dicen las fuentes, no inventes ni des información adicional que no estén presentes en las fuentes.\\n6. Debes seleccionar al menos 2 fuentes que sean Jurisprudencia o Doctrina, ya que estos ayudarán a dar contexto a las leyes en su aplicación.\\nRecomendaciones adicionales\\n- Dale más importancia a las fuentes que son extractos del documento que el usuario pidio.\\n- Conforma tu selección tanto de fuentes primarias como secundarias si esto ayuda a reponder mejor la pregunta.\\n- Las fuentes que selecciones es la única información que vas a tener disponible para responder a la pregunta, así que debes escoger fuentes que dentro de su contenido se encuentre la información.\\n- En tu razonamiento, si escogiste una fuente porque incluye cierta ley, artículo, teoría o mención de algo especial, qué ley, artículo, teoría, etc es a la que te refieres.\\n- No selecciones fuentes repetitivas, busca tener diversidad en tus fuentes.\\n- En el ID de la fuente encontrarás el número del chunk ej: '..._chunk10', esto significa que el siguiente chunk ('...chunk11') es el fragmento que le sigue al documento. Ten en cuenta esto para que sepas que si un contenido importante está cortado en un chunk, puedes agarrar el siguientes también.\\n- Ten en cuenta que los nombres de algunos codigos hacen referencia a una ley, decreto o articulo. Aqui tienes un listado para que te guies:\\n{codes_to_laws}\"\"\",\n",
    "    }\n",
    "\n",
    "    selection_messages = [\n",
    "        response_prompt_message,\n",
    "        *messages,\n",
    "        select_user_prompt_message,\n",
    "        select_prompt_message,\n",
    "        # select_instructions_prompt_message,\n",
    "    ]\n",
    "\n",
    "    print(\"🤖 Escogiendo las mejores fuentes para responder al usuario ...\")\n",
    "    selected_sources_to_add = []\n",
    "    sources_at_end = \"\"\n",
    "    selected_sources_completion = choose_sources_completion(selection_messages)\n",
    "    selected_sources = json.loads(\n",
    "        selected_sources_completion.choices[0].message.content\n",
    "    ).get(\"sources\")\n",
    "    for index, source in enumerate(selected_sources, start=1):\n",
    "        source_id = source.get(\"source_id\")\n",
    "        source_reason = source.get(\"reason\")\n",
    "        for source in sources_found_filtered:\n",
    "            if source[\"id\"] == source_id:\n",
    "                source[\"reason\"] = source_reason\n",
    "                sources_at_end += f\"{index}. {source[\"title\"]} - Página {source[\"page\"]}<br>\\n\"\n",
    "                selected_sources_to_add.append(source)\n",
    "        print(f\"{index}.[{source_id}]: {source_reason}\")\n",
    "\n",
    "    # return\n",
    "    sources_to_add = add_doc_to_context(selected_sources_to_add)\n",
    "    # TODO: Agregar hasta 3 por cada query que excedan 2.8/3 como score semántico.\n",
    "    # Quizás ponerle cap de 6 fuentes máximo en total ordenadas por score semántico, porque pueden ser 18 si ambas búsqueda es de 3 queries y tiene matchs fuertes\n",
    "    # TODO: Esto podría ser que los reorganice convirtiendo en vectores en la pregunta y comparándolos con los vectores de cada chunk, ChatGPT me dió esa idea... o cohere.\n",
    "\n",
    "    user_message = {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_input,\n",
    "    }\n",
    "    sources_prompt_message = {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": f\"Fuentes econtradas:\\n{sources_to_add}\",\n",
    "    }\n",
    "\n",
    "    response_messages = [\n",
    "        response_prompt_message,\n",
    "        *messages,\n",
    "        user_message,\n",
    "        sources_prompt_message,\n",
    "    ]\n",
    "\n",
    "    response_completion = generate_completion(response_messages)\n",
    "    print(response_completion.choices[0].message.content)\n",
    "    \n",
    "    \n",
    "    \n",
    "    print(f\"\\n\\n<p>{sources_at_end}</p>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probar con all > Dejarlo default mejor ✅\n",
    "Probar full text search > Malos resultados ✅\n",
    "Filtrar por semantic rerank score de 2 o más. ✅\n",
    "Filtrar por score de 1.7 o más. ✅\n",
    "Incluir hasta 25 fuentes por query.\n",
    "Otro proceso del mini 4o donde seleccione las mejores fuentes para responder la respuesta ✅\n",
    "Pedir que razone porqué escogió esos query ✅\n",
    "Probar corriendo el proyecto en un .py normal y ponerle timers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙎‍♂️ User: ¿Qué dice el artículo 250 de la Constitución?\n",
      "🤖 Generando queries con la pregunta del usuario ...\n"
     ]
    },
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m¿Qué dice el artículo 250 de la Constitución?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_conversation\u001b[39m(user_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_prompt:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mget_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[21], line 38\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m     31\u001b[0m query_messages \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     32\u001b[0m     query_prompt_message,\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;241m*\u001b[39mmessages,\n\u001b[1;32m     34\u001b[0m     query_user_prompt_message,\n\u001b[1;32m     35\u001b[0m ]\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🤖 Generando queries con la pregunta del usuario ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m first_query_completion \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m first_search_terms \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\n\u001b[1;32m     40\u001b[0m     first_query_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     41\u001b[0m )\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🤖 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(first_search_terms)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m búsquedas generadas ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[16], line 31\u001b[0m, in \u001b[0;36mgenerate_query\u001b[0;34m(query_messages)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_query\u001b[39m(query_messages):\n\u001b[1;32m     30\u001b[0m     log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(query_messages,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 31\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mclaude-3-haiku-20240307\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     35\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     log(response)\n\u001b[1;32m     38\u001b[0m     get_conversation_price(response, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhaiku\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_utils/_utils.py:274\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    272\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 274\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/resources/messages.py:878\u001b[0m, in \u001b[0;36mMessages.create\u001b[0;34m(self, max_tokens, messages, model, metadata, stop_sequences, stream, system, temperature, tool_choice, tools, top_k, top_p, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m DEPRECATED_MODELS:\n\u001b[1;32m    872\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe model \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is deprecated and will reach end-of-life on \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mDEPRECATED_MODELS[model]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mPlease migrate to a newer model. Visit https://docs.anthropic.com/en/docs/resources/model-deprecations for more information.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    874\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m    875\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,\n\u001b[1;32m    876\u001b[0m     )\n\u001b[0;32m--> 878\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/v1/messages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    880\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    881\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    882\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    883\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    884\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    885\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    886\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop_sequences\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_sequences\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    888\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msystem\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    889\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    891\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    892\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_k\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    893\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    894\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    895\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessage_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mMessageCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    896\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    897\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    898\u001b[0m \u001b[43m        \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    899\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    900\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mMessage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    902\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mRawMessageStreamEvent\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    903\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1260\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1246\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1248\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1255\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1256\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1257\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1258\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1259\u001b[0m     )\n\u001b[0;32m-> 1260\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:937\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    928\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    930\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    935\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    936\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 937\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    943\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/anthropic/_base_client.py:1041\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1038\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1040\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1041\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1043\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1044\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1045\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1049\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1050\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'type': 'error', 'error': {'type': 'invalid_request_error', 'message': 'Your credit balance is too low to access the Anthropic API. Please go to Plans & Billing to upgrade or purchase credits.'}}"
     ]
    }
   ],
   "source": [
    "run_conversation(\"¿Qué dice el artículo 250 de la Constitución?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙎‍♂️ User: Tienes el siguiente caso: Un estudiante de sexto de bachillerato de un colegio privado católico es echado del colegio por tener el pelo largo. Él laega que en el libre desarrollo de su personalidad, puede llevar el pelo como quiera. Por eso, presentó una tutela para que lo reintegren al colegio. El colegio ha contestado a la tutela indicando que, al ser una institución privada, ellos pueden reservarse el derecho de admisión y dictarse su propio manual de convivencia, en el que está prohibido llevar el pelo largo. Tú eres el juez de la tutela: ¿en qué sentido emites tu decisión?\n",
      "🤖 Generando queries con la pregunta del usuario ...\n",
      "💰 Conversation price: $436.248323 COP\n",
      "   This message: $4.927544 COP \n",
      "🤖 3 búsquedas generadas ...\n",
      "Necesito buscar la definición y alcance del libre desarrollo de la personalidad en la Constitución de Colombia para entender los derechos del estudiante.\n",
      "🔎 Buscando documentos: libre desarrollo de la personalidad en la Constitución de Colombia ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 44 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "Debo investigar si las instituciones privadas en Colombia tienen el derecho de admisión y si este derecho puede limitar el libre desarrollo de la personalidad de los estudiantes.\n",
      "🔎 Buscando documentos: derecho de admisión en instituciones privadas en Colombia ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 37 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "Necesito saber si los manuales de convivencia en instituciones educativas privadas en Colombia pueden establecer normas que limiten el libre desarrollo de la personalidad de los estudiantes y si estas normas son constitucionales.\n",
      "🔎 Buscando documentos: manual de convivencia en instituciones educativas privadas en Colombia ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 44 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "🤖 Generando nuevas búsquedas con la nueva información ...\n"
     ]
    },
    {
     "ename": "RateLimitError",
     "evalue": "Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j85f9s7yfkrvaszq50j89nn0` on tokens per minute (TPM): Limit 20000, Used 0, Requested 40808. Please try again in 1m2.424s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRateLimitError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[108], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mrun_conversation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mTienes el siguiente caso: Un estudiante de sexto de bachillerato de un colegio privado católico es echado del colegio por tener el pelo largo. Él laega que en el libre desarrollo de su personalidad, puede llevar el pelo como quiera. Por eso, presentó una tutela para que lo reintegren al colegio. El colegio ha contestado a la tutela indicando que, al ser una institución privada, ellos pueden reservarse el derecho de admisión y dictarse su propio manual de convivencia, en el que está prohibido llevar el pelo largo. Tú eres el juez de la tutela: ¿en qué sentido emites tu decisión?\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m      3\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[105], line 3\u001b[0m, in \u001b[0;36mrun_conversation\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_conversation\u001b[39m(user_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m user_prompt:\n\u001b[0;32m----> 3\u001b[0m         \u001b[43mget_answer\u001b[49m\u001b[43m(\u001b[49m\u001b[43muser_prompt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n",
      "Cell \u001b[0;32mIn[105], line 77\u001b[0m, in \u001b[0;36mget_answer\u001b[0;34m(user_prompt)\u001b[0m\n\u001b[1;32m     71\u001b[0m query_messages \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     72\u001b[0m     reasoning_results_prompt_message,\n\u001b[1;32m     73\u001b[0m     reasoning_prompt_message,\n\u001b[1;32m     74\u001b[0m ]\n\u001b[1;32m     76\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🤖 Generando nuevas búsquedas con la nueva información ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m second_query_completion \u001b[38;5;241m=\u001b[39m \u001b[43mgenerate_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_messages\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m second_search_terms \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(\n\u001b[1;32m     79\u001b[0m     second_query_completion\u001b[38;5;241m.\u001b[39mchoices[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mmessage\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m     80\u001b[0m )\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msearches\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m🤖 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(second_search_terms)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m búsquedas generadas ...\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[100], line 45\u001b[0m, in \u001b[0;36mgenerate_query\u001b[0;34m(query_messages)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_query\u001b[39m(query_messages):\n\u001b[1;32m     44\u001b[0m     log(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mjson\u001b[38;5;241m.\u001b[39mdumps(query_messages,\u001b[38;5;250m \u001b[39mindent\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m4\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 45\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mgroq_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchat\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mllama-3.1-70b-versatile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery_messages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mjson_object\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     log(response)\n\u001b[1;32m     52\u001b[0m     get_conversation_price(response, model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mllama-3-70b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py:287\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, parallel_tool_calls, presence_penalty, response_format, seed, stop, stream, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    146\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;241m*\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    175\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    176\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[1;32m    177\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[38;5;124;03m    Creates a model response for the given chat conversation.\u001b[39;00m\n\u001b[1;32m    179\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;124;03m      timeout: Override the client-level default timeout for this request, in seconds\u001b[39;00m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/openai/v1/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparallel_tool_calls\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparallel_tool_calls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    304\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    306\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    307\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    308\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    309\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    310\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    311\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    312\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    313\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    314\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    315\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/_base_client.py:1244\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1230\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1231\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1232\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1239\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1240\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1241\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1242\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1243\u001b[0m     )\n\u001b[0;32m-> 1244\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/_base_client.py:936\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    927\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    928\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    929\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    934\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    935\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 936\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    937\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    938\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    939\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    940\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    941\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    942\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Ariel - Projects/ariel-various-tests/.venv/lib/python3.12/site-packages/groq/_base_client.py:1039\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1036\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1038\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1039\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1041\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1042\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1043\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1047\u001b[0m     retries_taken\u001b[38;5;241m=\u001b[39moptions\u001b[38;5;241m.\u001b[39mget_max_retries(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_retries) \u001b[38;5;241m-\u001b[39m retries,\n\u001b[1;32m   1048\u001b[0m )\n",
      "\u001b[0;31mRateLimitError\u001b[0m: Error code: 429 - {'error': {'message': 'Rate limit reached for model `llama-3.1-70b-versatile` in organization `org_01j85f9s7yfkrvaszq50j89nn0` on tokens per minute (TPM): Limit 20000, Used 0, Requested 40808. Please try again in 1m2.424s. Visit https://console.groq.com/docs/rate-limits for more information.', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}"
     ]
    }
   ],
   "source": [
    "run_conversation(\n",
    "    \"Tienes el siguiente caso: Un estudiante de sexto de bachillerato de un colegio privado católico es echado del colegio por tener el pelo largo. Él laega que en el libre desarrollo de su personalidad, puede llevar el pelo como quiera. Por eso, presentó una tutela para que lo reintegren al colegio. El colegio ha contestado a la tutela indicando que, al ser una institución privada, ellos pueden reservarse el derecho de admisión y dictarse su propio manual de convivencia, en el que está prohibido llevar el pelo largo. Tú eres el juez de la tutela: ¿en qué sentido emites tu decisión?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙎‍♂️ User: ¿Cuáles son las principales sentencias de la Corte Constitucional sobre el aborto?\n",
      "🤖 Generando queries con la pregunta del usuario ...\n",
      "💰 Conversation price: $278.58392999999995 COP (In: 428534, Out: 6112, Total token: 434646)\n",
      "   This message: $1.2386100000000002 COP (In: 1442, Out: 143, Total token: 1585) \n",
      "🤖 3 búsquedas generadas ...\n",
      "Necesito buscar las sentencias más relevantes de la Corte Constitucional sobre el aborto para proporcionar un resumen de las decisiones y su impacto en la legislación y derechos en Colombia.\n",
      "🔎 Buscando documentos: principales sentencias Corte Constitucional aborto ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 50 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "Es importante encontrar documentos que contengan jurisprudencia específica de la Corte Constitucional relacionada con el aborto, para entender el contexto legal y las interpretaciones que se han dado.\n",
      "🔎 Buscando documentos: Corte Constitucional aborto jurisprudencia ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 42 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "Quiero investigar cómo la Corte Constitucional ha vinculado el aborto con los derechos fundamentales, lo que puede ayudar a entender la base legal de sus sentencias.\n",
      "🔎 Buscando documentos: aborto derechos fundamentales Corte Constitucional ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 50 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "🤖 Generando nuevas búsquedas con la nueva información ...\n",
      "💰 Conversation price: $301.87213499999996 COP (In: 465661, Out: 6297, Total token: 471958)\n",
      "   This message: $23.288204999999998 COP (In: 37127, Out: 185, Total token: 37312) \n",
      "🤖 3 búsquedas generadas ...\n",
      "Buscando 'principales sentencias Corte Constitucional aborto': Esta búsqueda se centra en identificar las sentencias más relevantes de la Corte Constitucional sobre el aborto, lo que permitirá obtener un resumen claro de las decisiones que han marcado la jurisprudencia en este tema.\n",
      "🔎 Buscando documentos: principales sentencias Corte Constitucional aborto ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 50 ...\n",
      "Buscando 'C-355 de 2006 Corte Constitucional aborto': La sentencia C-355 de 2006 es fundamental en la regulación del aborto en Colombia, ya que establece las causales en las que no se incurre en delito. Buscar información específica sobre esta sentencia ayudará a entender su impacto y relevancia.\n",
      "🔎 Buscando documentos: C-355 de 2006 Corte Constitucional aborto ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 48 ...\n",
      "Buscando 'jurisprudencia Corte Constitucional aborto derechos fundamentales': Esta búsqueda se enfoca en cómo la Corte Constitucional ha vinculado el aborto con los derechos fundamentales, lo que es crucial para comprender el contexto legal y los principios que sustentan las decisiones sobre el aborto en Colombia.\n",
      "🔎 Buscando documentos: jurisprudencia Corte Constitucional aborto derechos fundamentales ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 49 ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 150 pasaron 103 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 103 fuentes agregadas ...\n",
      "🤖 Escogiendo las mejores fuentes para responder al usuario ...\n",
      "💰 Conversation price: $334.54155 COP (In: 516594, Out: 6844, Total token: 523438)\n",
      "   This message: $32.669415 COP (In: 50933, Out: 547, Total token: 51480) \n",
      "1.[20240813222906ccc3552006pdf_chunk579]: La sentencia C-355 de 2006 es fundamental ya que establece las causales en las que el aborto no es considerado un delito, marcando un hito en la jurisprudencia colombiana sobre el aborto.\n",
      "2.[20240820161257ccc7542015pdf_chunk189]: Esta fuente proporciona un resumen de la sentencia C-355 de 2006, explicando su impacto en la despenalización del aborto en Colombia y su relación con los derechos fundamentales de las mujeres.\n",
      "3.[20240820201908cct3012016pdf_chunk91]: La sentencia T-301 de 2016 reitera y explica las reglas de la sentencia C-355 de 2006, analizando casos específicos y reafirmando el derecho al aborto en las causales establecidas.\n",
      "4.[20240820213515cct6972016pdf_chunk59]: La sentencia T-697 de 2016 aborda la importancia de la sentencia C-355 de 2006 y su aplicación en casos de aborto, lo que ayuda a entender la evolución de la jurisprudencia en este tema.\n",
      "5.[20240814120246cct9462008pdf_chunk35]: La sentencia T-946 de 2008 analiza la objeción de conciencia en el contexto del aborto, lo que es relevante para entender las implicaciones legales y éticas en la práctica del aborto en Colombia.\n",
      "6.[20240823072132ccc0552022pdf_chunk297]: La sentencia C-055 de 2022 discute la evolución de la jurisprudencia sobre el aborto y su relación con los derechos humanos, lo que proporciona un contexto actual sobre el tema.\n",
      "7.[20240823072132ccc0552022pdf_chunk69]: Esta fuente ofrece un análisis de la jurisprudencia reciente sobre el aborto, lo que es crucial para entender cómo se ha desarrollado la interpretación legal en Colombia.\n",
      "8.[20240823072132ccc0552022pdf_chunk124]: La sentencia C-055 de 2022 también aborda la despenalización del aborto y su relación con los derechos fundamentales, lo que es esencial para comprender el marco legal actual.\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 5 fuentes agregadas ...\n",
      "💰 Conversation price: $11124.7965 COP (In: 520026, Out: 7549, Total token: 527575)\n",
      "   This message: $113.71350000000001 COP (In: 3432, Out: 705, Total token: 4137) \n",
      "<p>Las principales sentencias de la Corte Constitucional de Colombia sobre el aborto son las siguientes:</p>\n",
      "\n",
      "<h2>Sentencia C-355 de 2006</h2>\n",
      "<p>Esta sentencia es fundamental ya que establece las causales en las que el aborto no es considerado un delito en Colombia. La Corte Constitucional determinó que la prohibición total del aborto era inconstitucional y estableció tres causales específicas en las que el aborto no sería penalizado:</p>\n",
      "<ul>\n",
      "  <li>Cuando la continuación del embarazo constituya peligro para la vida o la salud de la mujer, certificado por un médico.</li>\n",
      "  <li>Cuando exista grave malformación del feto que haga inviable su vida, certificado por un médico.</li>\n",
      "  <li>Cuando el embarazo sea resultado de una conducta constitutiva de acceso carnal o acto sexual sin consentimiento, abusivo, o de inseminación artificial o de transferencia de óvulo fecundado no consentidas, así como de incesto, y el hecho punible haya sido debidamente denunciado ante las autoridades competentes.</li>\n",
      "</ul>\n",
      "<p>Esta sentencia marcó un hito en la jurisprudencia colombiana sobre el aborto, al reconocer los derechos fundamentales de las mujeres en estas circunstancias [20240813222906ccc3552006pdf_chunk579] [20240820161257ccc7542015pdf_chunk189] [20240820213515cct6972016pdf_chunk59].</p>\n",
      "\n",
      "<h2>Sentencia T-301 de 2016</h2>\n",
      "<p>Esta sentencia reitera y explica las reglas de la sentencia C-355 de 2006, analizando casos específicos y reafirmando el derecho al aborto en las causales establecidas. En particular, se analizó el caso de una mujer embarazada con una malformación ósea en el feto, y la Corte Constitucional reafirmó las subreglas constitucionales aplicables al derecho a la interrupción voluntaria del embarazo [20240820201908cct3012016pdf_chunk91].</p>\n",
      "\n",
      "<h2>Sentencia T-697 de 2016</h2>\n",
      "<p>Esta sentencia aborda la importancia de la sentencia C-355 de 2006 y su aplicación en casos de aborto, ayudando a entender la evolución de la jurisprudencia en este tema. La Corte recordó que una prohibición total del aborto resultaba inconstitucional y que debía haber un ejercicio de ponderación que equilibrara el deber del Estado de proteger la vida del que está por nacer con los derechos fundamentales de la mujer [20240820213515cct6972016pdf_chunk59].</p>\n",
      "\n",
      "<h2>Sentencia T-946 de 2008</h2>\n",
      "<p>Esta sentencia analiza la objeción de conciencia en el contexto del aborto, lo que es relevante para entender las implicaciones legales y éticas en la práctica del aborto en Colombia. La Corte reafirmó las causales establecidas en la sentencia C-355 de 2006 y destacó la importancia de analizar cada caso en concreto [20240814120246cct9462008pdf_chunk35].</p>\n",
      "\n",
      "<p>Estas sentencias han sido fundamentales para la regulación del aborto en Colombia, estableciendo un marco legal que protege los derechos de las mujeres en situaciones específicas y garantizando su acceso a la interrupción voluntaria del embarazo bajo ciertas condiciones.</p>\n",
      "\n",
      "\n",
      "<p>1. CC - C355-2006 - Página 399<br>\n",
      "2. CC - C754-2015 - Página 95<br>\n",
      "3. CC - T301-2016 - Página 50<br>\n",
      "4. CC - T697-2016 - Página 32<br>\n",
      "5. CC - T946-2008 - Página 22<br>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\n",
    "    \"¿Cuáles son las principales sentencias de la Corte Constitucional sobre el aborto?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🙎‍♂️ User: ¿En qué casos la jurisprudencia ha reconocido la dosis de aprovisionamiento?\n",
      "🤖 Generando queries con la pregunta del usuario ...\n",
      "💰 Conversation price: $339.67434 COP (In: 521468, Out: 7712, Total token: 529180)\n",
      "   This message: $1.28781 COP (In: 1442, Out: 163, Total token: 1605) \n",
      "🤖 3 búsquedas generadas ...\n",
      "Necesito buscar información sobre la jurisprudencia que ha reconocido la dosis de aprovisionamiento, para entender en qué casos se ha aplicado y cuáles son los criterios utilizados por los tribunales.\n",
      "🔎 Buscando documentos: dosis de aprovisionamiento jurisprudencia ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 32 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "Es importante identificar casos específicos en los que se ha discutido la dosis de aprovisionamiento en la jurisprudencia, para tener ejemplos concretos y entender su aplicación práctica.\n",
      "🔎 Buscando documentos: casos jurisprudencia dosis de aprovisionamiento ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 35 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "Además de la jurisprudencia, es relevante buscar el concepto legal de dosis de aprovisionamiento para tener una base teórica que complemente la información sobre los casos y su reconocimiento en la jurisprudencia.\n",
      "🔎 Buscando documentos: dosis de aprovisionamiento concepto legal ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 33 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 25 fuentes agregadas ...\n",
      "🤖 Generando nuevas búsquedas con la nueva información ...\n",
      "💰 Conversation price: $364.37397 COP (In: 560850, Out: 7907, Total token: 568757)\n",
      "   This message: $24.69963 COP (In: 39382, Out: 195, Total token: 39577) \n",
      "🤖 3 búsquedas generadas ...\n",
      "Buscando 'casos jurisprudencia dosis de aprovisionamiento Colombia': Esta búsqueda se centra en encontrar casos específicos en los que la jurisprudencia colombiana ha reconocido la dosis de aprovisionamiento, lo que permitirá obtener ejemplos concretos y entender cómo se aplica este concepto en la práctica judicial.\n",
      "🔎 Buscando documentos: casos jurisprudencia dosis de aprovisionamiento Colombia ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 37 ...\n",
      "Buscando 'dosis de aprovisionamiento concepto legal Colombia': Es importante entender el concepto legal de dosis de aprovisionamiento en el contexto colombiano, ya que esto proporcionará una base teórica que complemente la información sobre los casos y su reconocimiento en la jurisprudencia.\n",
      "🔎 Buscando documentos: dosis de aprovisionamiento concepto legal Colombia ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 41 ...\n",
      "Buscando 'jurisprudencia sobre consumo personal y aprovisionamiento estupefacientes': Esta búsqueda se enfocará en la jurisprudencia relacionada con el consumo personal y la dosis de aprovisionamiento de estupefacientes, lo que ayudará a identificar criterios y principios que los tribunales han utilizado para tomar decisiones en estos casos.\n",
      "🔎 Buscando documentos: jurisprudencia sobre consumo personal y aprovisionamiento estupefacientes ...\n",
      "📋 Agarrando todos los resultados ...\n",
      "📋 Formateando resultados ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 50 pasaron 44 ...\n",
      "🧹 Eliminando fuentes irrelevantes o duplicadas ...\n",
      "🧹 Docs filtrados. De 150 pasaron 120 ...\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 120 fuentes agregadas ...\n",
      "🤖 Escogiendo las mejores fuentes para responder al usuario ...\n",
      "💰 Conversation price: $402.951075 COP (In: 621869, Out: 8334, Total token: 630203)\n",
      "   This message: $38.577104999999996 COP (In: 61019, Out: 427, Total token: 61446) \n",
      "1.[20240825154143csjstp5128202258665pdf_chunk18]: Esta fuente es de la Corte Suprema de Justicia y aborda directamente el concepto de dosis de aprovisionamiento, explicando su relación con el consumo personal y la no punibilidad de ciertas conductas.\n",
      "2.[20240825140531csjsp2989812112008pdf_chunk12]: Este extracto de la Corte Suprema de Justicia proporciona un contexto histórico y legal sobre la dosis de aprovisionamiento, además de mencionar la evolución de la jurisprudencia en relación con el consumo de estupefacientes.\n",
      "3.[20240825101013csjsp2695202155922pdf_chunk12]: Esta fuente también es de la Corte Suprema de Justicia y establece criterios sobre la finalidad del porte de estupefacientes, diferenciando entre consumo personal y tráfico, lo que es crucial para entender la jurisprudencia sobre la dosis de aprovisionamiento.\n",
      "4.[20240824123644csjap2581201748005pdf_chunk20]: Este extracto de la Corte Suprema de Justicia discute la antijuridicidad de la conducta de portar estupefacientes en cantidades ligeramente superiores a la dosis personal, lo que es relevante para la pregunta sobre la dosis de aprovisionamiento.\n",
      "5.[20240820213719tsdjmanizalessp20170018301pdf_chunk14]: Este extracto del Tribunal de Manizales proporciona un análisis sobre el porte de estupefacientes y su relación con el consumo personal, lo que ayuda a entender cómo se aplica la jurisprudencia en casos específicos.\n",
      "📋 Agregando fuentes al contexto ...\n",
      "📋 5 fuentes agregadas ...\n",
      "💰 Conversation price: $13381.785 COP (In: 625440, Out: 9110, Total token: 634550)\n",
      "   This message: $120.92950000000002 COP (In: 3571, Out: 776, Total token: 4347) \n",
      "<p>La jurisprudencia colombiana ha reconocido la figura de la \"dosis de aprovisionamiento\" en varios casos, principalmente diferenciando entre el consumo personal y el tráfico de estupefacientes. A continuación, se presentan algunos ejemplos relevantes:</p>\n",
      "\n",
      "<p><strong>1. Corte Suprema de Justicia - STP5128-2022:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia explicó que la \"dosis de aprovisionamiento\" se refiere a la cantidad de droga que una persona porta para consumir en varias oportunidades, no necesariamente en una sola ocasión. La Corte señaló que, en algunos casos, las personas pueden portar cantidades ligeramente superiores a la dosis personal permitida sin que esto implique una conducta lesiva del bien jurídico protegido, siempre y cuando se pueda demostrar que el porte está asociado al consumo personal y no al tráfico. La Corte también mencionó que cuando el exceso de la dosis personal es mínimo, se opera una presunción legal de antijuridicidad que admite prueba en contrario [20240825154143csjstp5128202258665pdf_chunk18].</p>\n",
      "\n",
      "<p><strong>2. Corte Suprema de Justicia - SP29898-2008:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia hizo referencia a la evolución histórica y legal del concepto de \"dosis de aprovisionamiento\". La Corte mencionó que, en el pasado, se consideraba una contravención penal portar una dosis personal con el exclusivo propósito de consumo personal. Sin embargo, esta contravención fue declarada inexequible por la Corte Constitucional, que argumentó que un Estado respetuoso de la dignidad humana no puede sustituir la educación por la represión como forma de controlar el consumo de sustancias [20240825140531csjsp2989812112008pdf_chunk12].</p>\n",
      "\n",
      "<p><strong>3. Corte Suprema de Justicia - SP2695-2021:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia estableció que la tipicidad de portar estupefacientes está supeditada a la finalidad del agente. Si la conducta persigue el aprovisionamiento para el consumo personal, no debe ser objeto de sanciones jurídico-penales. La Corte subrayó que el consumidor de estupefacientes, especialmente si es adicto, debe ser tratado como un sujeto de especial protección y destinatario de medidas administrativas de orden pedagógico, terapéutico y profiláctico [20240825101013csjsp2695202155922pdf_chunk12].</p>\n",
      "\n",
      "<p><strong>4. Corte Suprema de Justicia - AP2581-2017:</strong></p>\n",
      "<p>En esta sentencia, la Corte Suprema de Justicia precisó que, a pesar de la reforma constitucional y la modificación del artículo 376 del Código Penal, es posible considerar impunes las conductas dirigidas al consumo de estupefacientes en las dosis fijadas por la ley. La Corte reiteró que el porte de cantidades insignificantes o no desproporcionadas destinadas exclusivamente al consumo propio no incide sobre las categorías jurídicas que el legislador pretende proteger [20240824123644csjap2581201748005pdf_chunk20].</p>\n",
      "\n",
      "<p>En resumen, la jurisprudencia colombiana ha reconocido la \"dosis de aprovisionamiento\" en varios casos, destacando la importancia de diferenciar entre el consumo personal y el tráfico de estupefacientes. La Corte Suprema de Justicia ha enfatizado que el porte de estupefacientes con fines de consumo personal, incluso en cantidades ligeramente superiores a la dosis personal permitida, no debe ser objeto de sanciones penales, siempre y cuando se pueda demostrar que la finalidad es el consumo y no el tráfico.</p>\n",
      "\n",
      "\n",
      "<p>1. CSJ - STP5128-2022(58665) - Página 18<br>\n",
      "2. CSJ - SP29898(12-11-2008) - Página 12<br>\n",
      "3. CSJ - SP2695-2021(55922) - Página 12<br>\n",
      "4. CSJ - AP2581-2017(48005) - Página 17<br>\n",
      "5. TSDJ Manizales - SP2017-00183-01 - Página 13<br>\n",
      "</p>\n"
     ]
    }
   ],
   "source": [
    "run_conversation(\"¿Qué dice el artículo 103 del código penal?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_conversation(\"¿Cuándo se consuma el hurto?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
